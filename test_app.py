"""
ìŠ¤ë§ˆíŠ¸í•œ ì‡¼í•‘ ì•± - LangGraph ë²„ì „ (ìˆ˜ì •íŒ)
"""

import streamlit as st

# í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ì²« ë²ˆì§¸ë¡œ ì‹¤í–‰)
st.set_page_config(
    page_title="ìŠ¤ë§ˆíŠ¸í•œ ì‡¼í•‘ (LangGraph)",
    page_icon="ğŸ›’",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import pandas as pd
from supabase import create_client
from openai import OpenAI
import os
from dotenv import load_dotenv
from datetime import datetime
import time
import json
import re
import requests
from bs4 import BeautifulSoup
import numpy as np
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import io
import base64
import urllib.request

# LangGraph ê´€ë ¨
from typing import TypedDict, Annotated, List, Union, Dict
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage
import operator

# ì•± ì‹œì‘ ì‹œ í°íŠ¸ ìë™ ë‹¤ìš´ë¡œë“œ
@st.cache_resource
def ensure_font():
    """í°íŠ¸ íŒŒì¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ"""
    font_path = "./NanumGothic.ttf"
    
    if not os.path.exists(font_path):
        with st.spinner("í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
            try:
                # ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë‹¤ìš´ë¡œë“œ (ê³µì‹ GitHub ì €ì¥ì†Œ)
                url = "https://github.com/naver/nanumfont/raw/master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf"
                urllib.request.urlretrieve(url, font_path)
                st.success("âœ… í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"âŒ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # ëŒ€ì²´ URL ì‹œë„
                try:
                    alt_url = "https://cdn.jsdelivr.net/gh/naver/nanumfont@master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf"
                    urllib.request.urlretrieve(alt_url, font_path)
                    st.success("âœ… í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! (ëŒ€ì²´ ê²½ë¡œ)")
                except:
                    st.warning("âš ï¸ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. í‚¤ì›Œë“œê°€ ì˜ë¬¸ìœ¼ë¡œ í‘œì‹œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    return None
    
    return font_path

# í°íŠ¸ í™•ì¸ (í˜ì´ì§€ ì„¤ì • í›„ ì‹¤í–‰)
font_path = ensure_font()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL", "")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", "")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID") or st.secrets.get("NAVER_CLIENT_ID", "")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET") or st.secrets.get("NAVER_CLIENT_SECRET", "")

# LangSmith ì„¤ì • (ì„ íƒì )
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY") or st.secrets.get("LANGSMITH_API_KEY", "")
if LANGSMITH_API_KEY:
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_PROJECT"] = "smart-shopping-app"
    os.environ["LANGCHAIN_API_KEY"] = LANGSMITH_API_KEY
else:
    os.environ["LANGCHAIN_TRACING_V2"] = "false"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'dark_mode' not in st.session_state:
    st.session_state.dark_mode = False
if 'bookmarks' not in st.session_state:
    st.session_state.bookmarks = []
if 'search_history' not in st.session_state:
    st.session_state.search_history = []
if 'total_searches' not in st.session_state:
    st.session_state.total_searches = 0
if 'saved_products' not in st.session_state:
    st.session_state.saved_products = 0

# CSS ìŠ¤íƒ€ì¼ - ë‹¤í¬ëª¨ë“œ ì§€ì›
if st.session_state.dark_mode:
    bg_gradient = "linear-gradient(135deg, #1a1a2e 0%, #16213e 100%)"
    card_bg = "#0f3460"
    text_color = "#ffffff"
    secondary_text = "#e94560"
    header_gradient = "linear-gradient(135deg, #e94560 0%, #0f3460 100%)"
else:
    bg_gradient = "linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%)"
    card_bg = "white"
    text_color = "#333333"
    secondary_text = "#667eea"
    header_gradient = "linear-gradient(135deg, #667eea 0%, #764ba2 100%)"

st.markdown(f"""
<style>
    /* ì „ì²´ ë°°ê²½ ë° ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
    .stApp {{
        background: {bg_gradient};
    }}
    
    /* ë©”ì¸ í—¤ë” ê°œì„  */
    .main-header {{
        text-align: center;
        padding: 3rem 0;
        background: {header_gradient};
        color: white;
        border-radius: 20px;
        margin-bottom: 3rem;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        position: relative;
        overflow: hidden;
    }}
    
    .main-header h1 {{
        text-shadow: 3px 3px 6px rgba(0, 0, 0, 0.3), 
                     0 0 20px rgba(255, 255, 255, 0.2);
    }}
    
    .main-header p {{
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
    }}
    
    .main-header::before {{
        content: "";
        position: absolute;
        top: -50%;
        right: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: shimmer 3s infinite;
    }}
    
    @keyframes shimmer {{
        0% {{ transform: rotate(0deg); }}
        100% {{ transform: rotate(360deg); }}
    }}
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .search-card {{
        background: {card_bg};
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 5px 20px rgba(0, 0, 0, 0.08);
        margin-bottom: 2rem;
        color: {text_color};
    }}
    
    /* ì¥ì  ì„¹ì…˜ ê°œì„  */
    .pros-section {{
        background: linear-gradient(135deg, #d4f1d4 0%, #b8e6b8 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(40, 167, 69, 0.1);
        transition: transform 0.3s ease;
    }}
    
    .pros-section:hover {{
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(40, 167, 69, 0.15);
    }}
    
    /* ë‹¨ì  ì„¹ì…˜ ê°œì„  */
    .cons-section {{
        background: linear-gradient(135deg, #ffd6d6 0%, #ffb8b8 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(220, 53, 69, 0.1);
        transition: transform 0.3s ease;
    }}
    
    .cons-section:hover {{
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(220, 53, 69, 0.15);
    }}
    
    /* í”„ë¡œì„¸ìŠ¤ ì •ë³´ ê°œì„  */
    .process-info {{
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1.5rem 0;
        border: none;
        box-shadow: 0 3px 10px rgba(33, 150, 243, 0.1);
    }}
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stButton > button {{
        background: {header_gradient};
        color: white;
        border: none;
        padding: 0.75rem 2rem;
        border-radius: 30px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }}
    
    .stButton > button:hover {{
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }}
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input {{
        border-radius: 10px;
        border: 2px solid #e0e0e0;
        padding: 0.75rem 1rem;
        transition: all 0.3s ease;
        background: {card_bg};
        color: {text_color};
    }}
    
    .stTextInput > div > div > input:focus {{
        border-color: {secondary_text};
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }}
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .metric-card {{
        background: {card_bg};
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 3px 10px rgba(0, 0, 0, 0.08);
        text-align: center;
        transition: all 0.3s ease;
        color: {text_color};
    }}
    
    .metric-card:hover {{
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.12);
    }}
    
    /* ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ */
    @keyframes fadeIn {{
        from {{ opacity: 0; transform: translateY(20px); }}
        to {{ opacity: 1; transform: translateY(0); }}
    }}
    
    .fade-in {{
        animation: fadeIn 0.6s ease-out;
    }}
    
    /* ë¡œë”© ìŠ¤í”¼ë„ˆ */
    .spinner {{
        width: 50px;
        height: 50px;
        margin: 0 auto;
        border: 5px solid #f3f3f3;
        border-top: 5px solid {secondary_text};
        border-radius: 50%;
        animation: spin 1s linear infinite;
    }}
    
    @keyframes spin {{
        0% {{ transform: rotate(0deg); }}
        100% {{ transform: rotate(360deg); }}
    }}
    
    /* í”„ë¡œìŠ¤/ì½˜ìŠ¤ ì•„ì´í…œ */
    .pros-item, .cons-item {{
        background: white;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 8px;
        transition: all 0.3s ease;
        animation: fadeIn 0.5s ease-out;
    }}
    
    .pros-item {{
        border-left: 4px solid #28a745;
    }}
    
    .cons-item {{
        border-left: 4px solid #dc3545;
    }}
    
    .pros-item:hover, .cons-item:hover {{
        transform: translateX(5px);
        box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);
    }}
    
    /* ëª¨ë°”ì¼ ë°˜ì‘í˜• */
    @media (max-width: 768px) {{
        .main-header {{
            padding: 2rem 1rem;
            font-size: 0.9rem;
        }}
        .main-header h1 {{
            font-size: 1.8rem;
        }}
        .search-card {{
            padding: 1.5rem 1rem;
        }}
        .pros-section, .cons-section {{
            padding: 1.5rem 1rem;
        }}
    }}
    
    /* í”„ë¡œê·¸ë ˆìŠ¤ ë°” */
    .progress-bar {{
        width: 100%;
        height: 8px;
        background-color: #e0e0e0;
        border-radius: 4px;
        overflow: hidden;
        margin: 1rem 0;
    }}
    
    .progress-fill {{
        height: 100%;
        background: {header_gradient};
        animation: progress 2s ease-out;
    }}
    
    @keyframes progress {{
        from {{ width: 0%; }}
        to {{ width: 100%; }}
    }}
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    dark_mode = st.checkbox("ğŸŒ™ ë‹¤í¬ëª¨ë“œ", value=st.session_state.dark_mode)
    st.session_state.dark_mode = dark_mode
    
    st.markdown("### ğŸ“Œ ë¶ë§ˆí¬")
    if st.session_state.bookmarks:
        for bookmark in st.session_state.bookmarks:
            if st.button(f"ğŸ”– {bookmark}", key=f"bookmark_{bookmark}"):
                st.session_state.selected_bookmark = bookmark
    else:
        st.info("ë¶ë§ˆí¬ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    st.markdown("### ğŸ“Š ì‚¬ìš© í†µê³„")
    st.metric("ì´ ê²€ìƒ‰ ìˆ˜", f"{st.session_state.total_searches}íšŒ")
    st.metric("ì €ì¥ëœ ì œí’ˆ", f"{st.session_state.saved_products}ê°œ")

# í—¤ë”
st.markdown("""
<div class="main-header">
    <h1>ğŸ›’ ìŠ¤ë§ˆíŠ¸í•œ ì‡¼í•‘ (LangGraph Edition)</h1>
    <p style="font-size: 1.2rem; margin-top: 1rem;">
        LangGraphë¡œ êµ¬í˜„í•œ ì§€ëŠ¥í˜• ì œí’ˆ ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ
    </p>
    <p style="font-size: 0.9rem; margin-top: 0.5rem; opacity: 0.8;">
        <i class="fas fa-robot"></i> AIê°€ ìˆ˜ì²œ ê°œì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì¥ë‹¨ì ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤
    </p>
</div>
""", unsafe_allow_html=True)

# ========================
# LangGraph State ì •ì˜
# ========================

class SearchState(TypedDict):
    """ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ì˜ ìƒíƒœ"""
    product_name: str
    search_method: str  # "database" or "web_crawling"
    results: dict
    pros: List[str]
    cons: List[str]
    sources: List[dict]
    messages: Annotated[List[Union[HumanMessage, AIMessage]], operator.add]
    error: str

# ========================
# í¬ë¡¤ë§ í´ë˜ìŠ¤
# ========================

class ProConsLaptopCrawler:
    def __init__(self, naver_client_id, naver_client_secret):
        self.naver_headers = {
            "X-Naver-Client-Id": naver_client_id,
            "X-Naver-Client-Secret": naver_client_secret
        }
        self.openai_client = OpenAI(api_key=OPENAI_API_KEY)
        
        # í†µê³„
        self.stats = {
            'total_crawled': 0,
            'valid_pros_cons': 0,
            'api_errors': 0
        }
    
    def remove_html_tags(self, text):
        """HTML íƒœê·¸ ì œê±°"""
        text = BeautifulSoup(text, "html.parser").get_text()
        text = re.sub(r'<[^>]+>', '', text)
        return text.strip()
    
    def search_blog(self, query, display=20):
        """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰"""
        url = "https://openapi.naver.com/v1/search/blog"
        params = {
            "query": query,
            "display": display,
            "sort": "sim"
        }
        
        try:
            response = requests.get(url, headers=self.naver_headers, params=params)
            if response.status_code == 200:
                result = response.json()
                for item in result.get('items', []):
                    item['title'] = self.remove_html_tags(item['title'])
                    item['description'] = self.remove_html_tags(item['description'])
                return result
        except Exception as e:
            print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None
    
    def crawl_content(self, url):
        """ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§"""
        try:
            if "blog.naver.com" in url:
                parts = url.split('/')
                if len(parts) >= 5:
                    blog_id = parts[3]
                    post_no = parts[4].split('?')[0]
                    mobile_url = f"https://m.blog.naver.com/{blog_id}/{post_no}"
                    
                    response = requests.get(mobile_url, headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'html.parser')
                        
                        content = ""
                        for selector in ['div.se-main-container', 'div#postViewArea', 'div.post_ct']:
                            elem = soup.select_one(selector)
                            if elem:
                                content = elem.get_text(separator='\n', strip=True)
                                break
                        
                        if not content:
                            content = soup.get_text(separator='\n', strip=True)
                        
                        content = re.sub(r'\s+', ' ', content)
                        content = content.replace('\u200b', '')
                        
                        return content if len(content) > 300 else None
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None
    
    def extract_pros_cons_with_gpt(self, product_name, content):
        """ChatGPTë¡œ ì¥ë‹¨ì  ì¶”ì¶œ"""
        if not content or len(content) < 200:
            return None
        
        content_preview = content[:1500]
        
        prompt = f"""ë‹¤ìŒì€ "{product_name}"ì— ëŒ€í•œ ë¸”ë¡œê·¸ ë¦¬ë·°ì…ë‹ˆë‹¤.

[ë¸”ë¡œê·¸ ë‚´ìš©]
{content_preview}

ìœ„ ë‚´ìš©ì—ì„œ {product_name}ì˜ ì¥ì ê³¼ ë‹¨ì ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì‹¤ì œ ì‚¬ìš© ê²½í—˜ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ë‚´ìš©ë§Œ í¬í•¨í•˜ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ì¥ì :
- (êµ¬ì²´ì ì¸ ì¥ì  1)
- (êµ¬ì²´ì ì¸ ì¥ì  2)
- (êµ¬ì²´ì ì¸ ì¥ì  3)

ë‹¨ì :
- (êµ¬ì²´ì ì¸ ë‹¨ì  1)
- (êµ¬ì²´ì ì¸ ë‹¨ì  2)
- (êµ¬ì²´ì ì¸ ë‹¨ì  3)

ë§Œì•½ ì¥ë‹¨ì  ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ "ì •ë³´ ë¶€ì¡±"ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”."""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì œí’ˆ ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš© ê²½í—˜ì— ê¸°ë°˜í•œ ì¥ë‹¨ì ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            result = response.choices[0].message.content.strip()
            
            if result and "ì •ë³´ ë¶€ì¡±" not in result:
                pros = []
                cons = []
                
                lines = result.split('\n')
                current_section = None
                
                for line in lines:
                    line = line.strip()
                    if 'ì¥ì :' in line or 'ì¥ì  :' in line:
                        current_section = 'pros'
                    elif 'ë‹¨ì :' in line or 'ë‹¨ì  :' in line:
                        current_section = 'cons'
                    elif line.startswith('-') and current_section:
                        point = line[1:].strip()
                        if point and len(point) > 5:
                            if current_section == 'pros':
                                pros.append(point)
                            else:
                                cons.append(point)
                
                if pros or cons:
                    self.stats['valid_pros_cons'] += 1
                    return {
                        'pros': pros[:5],
                        'cons': cons[:5]
                    }
            
            return None
                
        except Exception as e:
            self.stats['api_errors'] += 1
            print(f"GPT API ì˜¤ë¥˜: {str(e)[:100]}")
            return None
    
    def deduplicate_points(self, points):
        """ìœ ì‚¬í•œ ì¥ë‹¨ì  ì¤‘ë³µ ì œê±°"""
        if not points:
            return []
        
        unique_points = []
        seen_keywords = set()
        
        for point in points:
            keywords = set(word for word in point.split() if len(word) > 2)
            
            if len(keywords & seen_keywords) < len(keywords) * 0.5:
                unique_points.append(point)
                seen_keywords.update(keywords)
            
            if len(unique_points) >= 10:
                break
        
        return unique_points

# ========================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ========================

def show_loading_animation():
    """ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ í‘œì‹œ"""
    loading_placeholder = st.empty()
    loading_placeholder.markdown("""
    <div style="text-align: center; padding: 3rem;">
        <div class="spinner"></div>
        <p style="margin-top: 1rem; color: #667eea; font-weight: 600;">
            <i class="fas fa-brain"></i> AIê°€ ì œí’ˆ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...
        </p>
        <div class="progress-bar">
            <div class="progress-fill"></div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    return loading_placeholder

def create_pros_cons_chart(pros_count, cons_count):
    """ì¥ë‹¨ì  ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure(data=[
        go.Bar(
            name='ì¥ì ',
            x=['ë¶„ì„ ê²°ê³¼'],
            y=[pros_count],
            marker_color='#28a745',
            text=f'{pros_count}ê°œ',
            textposition='auto',
            hovertemplate='ì¥ì : %{y}ê°œ<extra></extra>'
        ),
        go.Bar(
            name='ë‹¨ì ',
            x=['ë¶„ì„ ê²°ê³¼'],
            y=[cons_count],
            marker_color='#dc3545',
            text=f'{cons_count}ê°œ',
            textposition='auto',
            hovertemplate='ë‹¨ì : %{y}ê°œ<extra></extra>'
        )
    ])
    
    fig.update_layout(
        barmode='group',
        height=300,
        margin=dict(l=0, r=0, t=30, b=0),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(size=14),
        showlegend=True,
        legend=dict(x=0.3, y=1.1, orientation='h'),
        xaxis=dict(showgrid=False, showticklabels=False),
        yaxis=dict(showgrid=True, gridcolor='rgba(0,0,0,0.1)'),
        bargap=0.3
    )
    
    return fig

def extract_keywords(texts):
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ë¶ˆìš©ì–´ ì •ì˜
    stopwords = {'ìˆ˜', 'ìˆìŠµë‹ˆë‹¤', 'ìˆì–´ìš”', 'ìˆìŒ', 'ì¢‹ìŠµë‹ˆë‹¤', 'ì¢‹ì•„ìš”', 'ì¢‹ìŒ', 
                 'ë‚˜ì©ë‹ˆë‹¤', 'ë‚˜ë¹ ìš”', 'ë‚˜ì¨', 'ì•ŠìŠµë‹ˆë‹¤', 'ì•Šì•„ìš”', 'ì•ŠìŒ',
                 'ì…ë‹ˆë‹¤', 'ì´ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ê°™ë‹¤',
                 'ìœ„í•´', 'í†µí•´', 'ëŒ€í•´', 'ë§¤ìš°', 'ì •ë§', 'ë„ˆë¬´', 'ì¡°ê¸ˆ',
                 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ë˜í•œ', 'ë•Œë¬¸', 'ê²½ìš°'}
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•˜ê³  í‚¤ì›Œë“œ ì¶”ì¶œ
    all_text = ' '.join(texts)
    words = re.findall(r'[ê°€-í£]+', all_text)
    
    # 2ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ í•„í„°ë§í•˜ê³  ë¶ˆìš©ì–´ ì œê±°
    words = [word for word in words if len(word) >= 2 and word not in stopwords]
    
    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    word_freq = Counter(words)
    
    return word_freq

def create_wordcloud(texts, title, color_scheme):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not texts:
        return None
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    word_freq = extract_keywords(texts)
    
    if not word_freq:
        return None
    
    # matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
    import matplotlib.pyplot as plt
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ í°íŠ¸ íŒŒì¼ ìš°ì„  ì‚¬ìš©
    font_path = "./NanumGothic.ttf"
    
    # í°íŠ¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„
    if not os.path.exists(font_path):
        font_paths = [
            "NanumGothic.ttf",  # ê°™ì€ ë””ë ‰í† ë¦¬
            "./fonts/NanumGothic.ttf",  # fonts í´ë”
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",  # Linux
            "C:/Windows/Fonts/malgun.ttf",  # Windows
            "/System/Library/Fonts/AppleSDGothicNeo.ttc"  # macOS
        ]
        
        for path in font_paths:
            if os.path.exists(path):
                font_path = path
                break
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    plt.figure(figsize=(10, 6), facecolor='white')
    
    if font_path and os.path.exists(font_path):
        try:
            wordcloud = WordCloud(
                width=800,
                height=400,
                background_color='white',
                colormap=color_scheme,
                font_path=font_path,
                relative_scaling=0.5,
                min_font_size=12,
                max_words=30,
                prefer_horizontal=0.7,
                margin=10
            ).generate_from_frequencies(word_freq)
            
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.tight_layout(pad=0)
            
            # ì´ë¯¸ì§€ë¥¼ bytesë¡œ ë³€í™˜
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=150, bbox_inches='tight', facecolor='white', edgecolor='none')
            buf.seek(0)
            plt.close()
            
            return buf
            
        except Exception as e:
            plt.close()
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    else:
        st.warning(f"í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. NanumGothic.ttf íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return None

def create_text_cloud(texts, title, color):
    """ì›Œë“œí´ë¼ìš°ë“œ ëŒ€ì‹  í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œê°í™”"""
    if not texts:
        return
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    word_freq = extract_keywords(texts)
    
    if not word_freq:
        return
    
    # ìƒìœ„ 20ê°œ í‚¤ì›Œë“œ
    top_words = word_freq.most_common(20)
    
    # ìµœëŒ€ ë¹ˆë„ìˆ˜
    max_freq = top_words[0][1] if top_words else 1
    
    # HTMLë¡œ ì›Œë“œí´ë¼ìš°ë“œ ìŠ¤íƒ€ì¼ í‘œí˜„
    html_words = []
    for word, freq in top_words:
        # ë¹ˆë„ìˆ˜ì— ë”°ë¥¸ í¬ê¸° ê³„ì‚° (1rem ~ 3rem)
        size = 1 + (freq / max_freq) * 2
        # ë¹ˆë„ìˆ˜ì— ë”°ë¥¸ íˆ¬ëª…ë„ (0.5 ~ 1.0)
        opacity = 0.5 + (freq / max_freq) * 0.5
        
        html_words.append(
            f'<span style="font-size: {size}rem; color: {color}; opacity: {opacity}; '
            f'margin: 0.3rem; display: inline-block; font-weight: bold;">{word}</span>'
        )
    
    # ëœë¤í•˜ê²Œ ì„ê¸°
    import random
    random.shuffle(html_words)
    
    # HTML ì¶œë ¥
    st.markdown(f"""
    <div style="text-align: center; padding: 2rem; background: white; 
                border-radius: 15px; border: 2px solid {color}20;">
        <h4 style="color: {color}; margin-bottom: 1rem;">{title}</h4>
        <div style="line-height: 2.5;">
            {''.join(html_words)}
        </div>
    </div>
    """, unsafe_allow_html=True)

def display_wordclouds(pros, cons):
    """ì¥ë‹¨ì  ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ"""
    col1, col2 = st.columns(2)
    
    with col1:
        if pros:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #d4f1d4 0%, #b8e6b8 100%); border-radius: 15px;">
                <h3 style="color: #28a745; margin: 0;">
                    <i class="fas fa-check-circle"></i> ì¥ì  í‚¤ì›Œë“œ
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # ì¥ì  ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹œë„
            pros_wordcloud = create_wordcloud(pros, "", "Greens")
            if pros_wordcloud:
                st.image(pros_wordcloud, use_container_width=True)
            else:
                # ì›Œë“œí´ë¼ìš°ë“œ ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œê°í™”
                create_text_cloud(pros, "ì¥ì  í‚¤ì›Œë“œ ë¶„ì„", "#28a745")
            
            # ì£¼ìš” í‚¤ì›Œë“œ í‘œì‹œ
            keywords = extract_keywords(pros)
            if keywords:
                st.markdown("**ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ:**")
                top_keywords = keywords.most_common(5)
                keyword_html = " ".join([f'<span style="background: #d4f1d4; padding: 0.2rem 0.5rem; border-radius: 15px; margin: 0.2rem; display: inline-block;">{word} ({count})</span>' 
                                        for word, count in top_keywords])
                st.markdown(keyword_html, unsafe_allow_html=True)
    
    with col2:
        if cons:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #ffd6d6 0%, #ffb8b8 100%); border-radius: 15px;">
                <h3 style="color: #dc3545; margin: 0;">
                    <i class="fas fa-times-circle"></i> ë‹¨ì  í‚¤ì›Œë“œ
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # ë‹¨ì  ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹œë„
            cons_wordcloud = create_wordcloud(cons, "", "Reds")
            if cons_wordcloud:
                st.image(cons_wordcloud, use_container_width=True)
            else:
                # ì›Œë“œí´ë¼ìš°ë“œ ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹œê°í™”
                create_text_cloud(cons, "ë‹¨ì  í‚¤ì›Œë“œ ë¶„ì„", "#dc3545")
            
            # ì£¼ìš” í‚¤ì›Œë“œ í‘œì‹œ
            keywords = extract_keywords(cons)
            if keywords:
                st.markdown("**ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ:**")
                top_keywords = keywords.most_common(5)
                keyword_html = " ".join([f'<span style="background: #ffd6d6; padding: 0.2rem 0.5rem; border-radius: 15px; margin: 0.2rem; display: inline-block;">{word} ({count})</span>' 
                                        for word, count in top_keywords])
                st.markdown(keyword_html, unsafe_allow_html=True)

def create_trend_chart(sources):
    """ì‹œê°„ë³„ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„±"""
    if not sources:
        return None
    
    # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
    date_counts = {}
    for source in sources:
        date_str = source.get('date', '')
        if date_str:
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYYMMDD -> YYYY-MM-DD)
            try:
                if len(date_str) == 8:
                    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                    date = datetime.strptime(formatted_date, '%Y-%m-%d')
                    month_year = date.strftime('%Y-%m')
                    date_counts[month_year] = date_counts.get(month_year, 0) + 1
            except:
                pass
    
    if not date_counts:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ë‚ ì§œê°€ ì—†ì„ ê²½ìš°)
        current_date = datetime.now()
        for i in range(6):
            month = current_date.replace(day=1) - pd.DateOffset(months=i)
            month_str = month.strftime('%Y-%m')
            date_counts[month_str] = np.random.randint(5, 20)
    
    # ì •ë ¬
    sorted_dates = sorted(date_counts.items())
    dates = [item[0] for item in sorted_dates]
    counts = [item[1] for item in sorted_dates]
    
    # ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    # ì„  ê·¸ë˜í”„
    fig.add_trace(go.Scatter(
        x=dates,
        y=counts,
        mode='lines+markers',
        name='ë¦¬ë·° ìˆ˜',
        line=dict(color='#667eea', width=3),
        marker=dict(size=10, color='#667eea'),
        fill='tozeroy',
        fillcolor='rgba(102, 126, 234, 0.1)'
    ))
    
    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        title={
            'text': 'ğŸ“ˆ ì›”ë³„ ë¦¬ë·° ì¶”ì´',
            'font': {'size': 20, 'color': text_color}
        },
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ë¦¬ë·° ìˆ˜',
        height=350,
        margin=dict(l=0, r=0, t=50, b=0),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        xaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            showline=True,
            linecolor='rgba(0,0,0,0.2)'
        ),
        yaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            showline=True,
            linecolor='rgba(0,0,0,0.2)'
        ),
        hovermode='x unified'
    )
    
    # ì£¼ì„ ì¶”ê°€ (ìµœê³ ì )
    if counts:
        max_idx = counts.index(max(counts))
        fig.add_annotation(
            x=dates[max_idx],
            y=counts[max_idx],
            text=f"ìµœê³ : {counts[max_idx]}ê±´",
            showarrow=True,
            arrowhead=2,
            arrowsize=1,
            arrowwidth=2,
            arrowcolor="#667eea",
            ax=0,
            ay=-40,
            font=dict(size=12, color=text_color),
            bgcolor="white",
            bordercolor="#667eea",
            borderwidth=2,
            borderpad=4,
            opacity=0.9
        )
    
    return fig

# ========================
# LangGraph ë…¸ë“œ í•¨ìˆ˜ë“¤
# ========================

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def get_supabase_client():
    return create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

@st.cache_resource
def get_crawler():
    return ProConsLaptopCrawler(NAVER_CLIENT_ID, NAVER_CLIENT_SECRET) if NAVER_CLIENT_ID and NAVER_CLIENT_SECRET else None

def search_database(state: SearchState) -> SearchState:
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œí’ˆ ê²€ìƒ‰"""
    product_name = state["product_name"]
    supabase = get_supabase_client()
    
    if not supabase:
        state["messages"].append(
            AIMessage(content="âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        )
        state["results"] = {"data": None}
        return state
    
    state["messages"].append(
        HumanMessage(content=f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{product_name}' ê²€ìƒ‰ ì¤‘...")
    )
    
    try:
        # ì •í™•í•œ ë§¤ì¹­ë§Œ ì‹œë„
        exact_match = supabase.table('laptop_pros_cons').select("*").eq('product_name', product_name).execute()
        if exact_match.data:
            state["search_method"] = "database"
            state["results"] = {"data": exact_match.data}
            state["messages"].append(
                AIMessage(content=f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{product_name}' ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! ({len(exact_match.data)}ê°œ í•­ëª©)")
            )
            return state
        
        state["messages"].append(
            AIMessage(content=f"âŒ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{product_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
        )
        state["results"] = {"data": None}
        return state
        
    except Exception as e:
        state["error"] = str(e)
        state["messages"].append(
            AIMessage(content=f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        )
        state["results"] = {"data": None}
        return state

def crawl_web(state: SearchState) -> SearchState:
    """ì›¹ì—ì„œ ì œí’ˆ ì •ë³´ í¬ë¡¤ë§"""
    if state["results"].get("data"):  # ì´ë¯¸ DBì—ì„œ ì°¾ì€ ê²½ìš°
        return state
    
    product_name = state["product_name"]
    state["search_method"] = "web_crawling"
    crawler = get_crawler()
    
    if not crawler:
        state["messages"].append(
            AIMessage(content="âš ï¸ ì›¹ í¬ë¡¤ë§ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        )
        return state
    
    state["messages"].append(
        HumanMessage(content=f"ğŸŒ ì›¹ì—ì„œ '{product_name}' ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘...")
    )
    
    # ìƒ˜í”Œ ë°ì´í„° (API í‚¤ê°€ ì—†ì„ ë•Œ)
    if not OPENAI_API_KEY:
        state["pros"] = [
            "ê°€ë³ê³  íœ´ëŒ€ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤",
            "ë°°í„°ë¦¬ ì§€ì† ì‹œê°„ì´ ê¹ë‹ˆë‹¤",
            "ë””ìŠ¤í”Œë ˆì´ê°€ ì„ ëª…í•©ë‹ˆë‹¤",
            "ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤",
            "ë””ìì¸ì´ ì„¸ë ¨ë˜ì—ˆìŠµë‹ˆë‹¤"
        ]
        state["cons"] = [
            "ê°€ê²©ì´ ë¹„ìŒ‰ë‹ˆë‹¤",
            "í¬íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤",
            "í‚¤ë³´ë“œ í‚¤ê°ì´ ì•„ì‰½ìŠµë‹ˆë‹¤"
        ]
        state["messages"].append(
            AIMessage(content="ğŸ“Œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤ (API í‚¤ ì„¤ì • í•„ìš”)")
        )
        return state
    
    all_pros = []
    all_cons = []
    sources = []
    
    # ê²€ìƒ‰ ì¿¼ë¦¬
    search_queries = [
        f"{product_name} ì¥ë‹¨ì  ì‹¤ì‚¬ìš©",
        f"{product_name} ë‹¨ì  í›„ê¸°",
        f"{product_name} ì¥ì  ë¦¬ë·°"
    ]
    
    for query in search_queries:
        state["messages"].append(
            AIMessage(content=f"ğŸ” ê²€ìƒ‰ì–´: '{query}'")
        )
        
        # ë„¤ì´ë²„ ê²€ìƒ‰
        result = crawler.search_blog(query, display=10)
        if not result or 'items' not in result:
            continue
        
        posts = result['items']
        state["messages"].append(
            AIMessage(content=f"â†’ {len(posts)}ê°œ í¬ìŠ¤íŠ¸ ë°œê²¬")
        )
        
        # ê° í¬ìŠ¤íŠ¸ ì²˜ë¦¬
        for idx, post in enumerate(posts[:5]):
            state["messages"].append(
                AIMessage(content=f"ğŸ“– ë¶„ì„ ì¤‘: {post['title'][:40]}...")
            )
            
            # í¬ë¡¤ë§
            content = crawler.crawl_content(post['link'])
            if not content:
                continue
            
            crawler.stats['total_crawled'] += 1
            
            # ì¥ë‹¨ì  ì¶”ì¶œ
            pros_cons = crawler.extract_pros_cons_with_gpt(product_name, content)
            
            if pros_cons:
                all_pros.extend(pros_cons['pros'])
                all_cons.extend(pros_cons['cons'])
                sources.append({
                    'title': post['title'],
                    'link': post['link'],
                    'date': post.get('postdate', '')
                })
                
                state["messages"].append(
                    AIMessage(content=f"âœ“ ì¥ì  {len(pros_cons['pros'])}ê°œ, ë‹¨ì  {len(pros_cons['cons'])}ê°œ ì¶”ì¶œ")
                )
            
            time.sleep(1)
        
        time.sleep(2)
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
    unique_pros = crawler.deduplicate_points(all_pros)
    unique_cons = crawler.deduplicate_points(all_cons)
    
    state["pros"] = unique_pros
    state["cons"] = unique_cons
    state["sources"] = sources[:10]
    
    if state["pros"] or state["cons"]:
        state["messages"].append(
            AIMessage(content=f"ğŸ‰ ì›¹ í¬ë¡¤ë§ ì™„ë£Œ! ì´ ì¥ì  {len(state['pros'])}ê°œ, ë‹¨ì  {len(state['cons'])}ê°œ ìˆ˜ì§‘")
        )
        
        # DBì— ì €ì¥
        try:
            supabase = get_supabase_client()
            if supabase:
                data = []
                
                for pro in state["pros"]:
                    data.append({
                        'product_name': product_name,
                        'type': 'pro',
                        'content': pro
                    })
                
                for con in state["cons"]:
                    data.append({
                        'product_name': product_name,
                        'type': 'con',
                        'content': con
                    })
                
                if data:
                    supabase.table('laptop_pros_cons').insert(data).execute()
                    state["messages"].append(
                        AIMessage(content="ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì™„ë£Œ!")
                    )
                    st.session_state.saved_products += 1
        except Exception as e:
            state["messages"].append(
                AIMessage(content=f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            )
    else:
        state["messages"].append(
            AIMessage(content=f"ğŸ˜¢ '{product_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        )
    
    # ìµœì¢… í†µê³„
    state["messages"].append(
        AIMessage(content=f"ğŸ“Š í¬ë¡¤ë§ í†µê³„: ì´ {crawler.stats['total_crawled']}ê°œ í˜ì´ì§€, ìœ íš¨ ì¶”ì¶œ {crawler.stats['valid_pros_cons']}ê°œ")
    )
    
    return state

def process_results(state: SearchState) -> SearchState:
    """ê²°ê³¼ ì²˜ë¦¬ ë° ì •ë¦¬"""
    if state["search_method"] == "database" and state["results"].get("data"):
        # DB ê²°ê³¼ ì²˜ë¦¬
        data = state["results"]["data"]
        state["pros"] = [item['content'] for item in data if item['type'] == 'pro']
        state["cons"] = [item['content'] for item in data if item['type'] == 'con']
        state["sources"] = []
        
        state["messages"].append(
            AIMessage(content=f"ğŸ“‹ ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ: ì¥ì  {len(state['pros'])}ê°œ, ë‹¨ì  {len(state['cons'])}ê°œ")
        )
    
    return state

def should_search_web(state: SearchState) -> str:
    """ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨"""
    if state["results"].get("data"):
        return "process"
    else:
        return "crawl"

# ========================
# LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
# ========================

@st.cache_resource
def create_search_workflow():
    workflow = StateGraph(SearchState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("search_db", search_database)
    workflow.add_node("crawl_web", crawl_web)
    workflow.add_node("process", process_results)
    
    # ì—£ì§€ ì„¤ì •
    workflow.set_entry_point("search_db")
    workflow.add_conditional_edges(
        "search_db",
        should_search_web,
        {
            "crawl": "crawl_web",
            "process": "process"
        }
    )
    workflow.add_edge("crawl_web", "process")
    workflow.add_edge("process", END)
    
    return workflow.compile()

# ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
search_app = create_search_workflow()

# ========================
# Streamlit UI
# ========================

# ê²€ìƒ‰ ì„¹ì…˜
col1, col2, col3 = st.columns([1, 3, 1])

with col2:
    st.markdown('<div class="search-card fade-in">', unsafe_allow_html=True)
    
    st.markdown("""
    <h3 style="text-align: center; color: #333; margin-bottom: 1.5rem;">
        <i class="fas fa-search"></i> ì–´ë–¤ ì œí’ˆì„ ì°¾ê³  ê³„ì‹ ê°€ìš”?
    </h3>
    """, unsafe_allow_html=True)
    
    # ë¶ë§ˆí¬ì—ì„œ ì„ íƒëœ í•­ëª©ì´ ìˆìœ¼ë©´ ìë™ ì…ë ¥
    default_value = ""
    if 'selected_bookmark' in st.session_state:
        default_value = st.session_state.selected_bookmark
        del st.session_state.selected_bookmark
    
    product_name = st.text_input(
        "ì œí’ˆëª… ì…ë ¥",  # label ì¶”ê°€
        placeholder="ì˜ˆ: ë§¥ë¶ í”„ë¡œ M3, LG ê·¸ë¨ 2024, ê°¤ëŸ­ì‹œë¶4 í”„ë¡œ",
        value=default_value,
        label_visibility="collapsed"  # labelì€ ìˆ¨ê¸°ë˜ ê²½ê³  ë°©ì§€
    )
    
    col_btn1, col_btn2, col_btn3 = st.columns([2, 2, 1])
    with col_btn1:
        search_button = st.button("ğŸ” ê²€ìƒ‰í•˜ê¸°", use_container_width=True, type="primary")
    with col_btn2:
        show_process = st.checkbox("ğŸ”§ í”„ë¡œì„¸ìŠ¤ ë³´ê¸°", value=True)
    with col_btn3:
        if product_name and st.button("ğŸ“Œ", help="ë¶ë§ˆí¬ì— ì¶”ê°€"):
            if product_name not in st.session_state.bookmarks:
                st.session_state.bookmarks.append(product_name)
                st.success("ë¶ë§ˆí¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.session_state.total_searches += 1
    
    st.markdown('</div>', unsafe_allow_html=True)

# ê²€ìƒ‰ ì‹¤í–‰
if search_button and product_name:
    loading_placeholder = show_loading_animation()
    
    # LangGraph ì‹¤í–‰
    initial_state = {
        "product_name": product_name,
        "search_method": "",
        "results": {},
        "pros": [],
        "cons": [],
        "sources": [],
        "messages": [],
        "error": ""
    }
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    final_state = search_app.invoke(initial_state)
    
    # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ ì œê±°
    loading_placeholder.empty()
    
    # í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ í‘œì‹œ
    if show_process and final_state["messages"]:
        with st.expander("ğŸ”§ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤", expanded=False):
            for msg in final_state["messages"]:
                if isinstance(msg, HumanMessage):
                    st.write(f"ğŸ‘¤ {msg.content}")
                else:
                    st.write(f"ğŸ¤– {msg.content}")
    
    # ê²°ê³¼ í‘œì‹œ
    if final_state["pros"] or final_state["cons"]:
        # ê²€ìƒ‰ ì •ë³´
        st.markdown(f"""
        <div class="process-info fade-in">
            <strong><i class="fas fa-info-circle"></i> ê²€ìƒ‰ ë°©ë²•:</strong> {
                'ë°ì´í„°ë² ì´ìŠ¤' if final_state["search_method"] == "database" else 'ì›¹ í¬ë¡¤ë§'
            } | 
            <strong><i class="fas fa-thumbs-up"></i> ì¥ì :</strong> {len(final_state["pros"])}ê°œ | 
            <strong><i class="fas fa-thumbs-down"></i> ë‹¨ì :</strong> {len(final_state["cons"])}ê°œ
        </div>
        """, unsafe_allow_html=True)
        
        # ì¥ë‹¨ì  ìƒì„¸ í‘œì‹œ (ì›Œë“œí´ë¼ìš°ë“œë³´ë‹¤ ë¨¼ì €)
        st.markdown("---")
        st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="pros-section fade-in">
                <h3 style="color: #28a745; margin-bottom: 1.5rem;">
                    <i class="fas fa-check-circle"></i> ì¥ì 
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            if final_state["pros"]:
                for idx, pro in enumerate(final_state["pros"], 1):
                    st.markdown(f"""
                    <div class="pros-item">
                        <span style="color: #28a745; font-weight: bold;">
                            <i class="fas fa-check"></i> {idx}.
                        </span> {pro}
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.write("ì¥ì  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.markdown("""
            <div class="cons-section fade-in">
                <h3 style="color: #dc3545; margin-bottom: 1.5rem;">
                    <i class="fas fa-times-circle"></i> ë‹¨ì 
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            if final_state["cons"]:
                for idx, con in enumerate(final_state["cons"], 1):
                    st.markdown(f"""
                    <div class="cons-item">
                        <span style="color: #dc3545; font-weight: bold;">
                            <i class="fas fa-times"></i> {idx}.
                        </span> {con}
                    </div>
                    """, unsafe_allow_html=True)
            else:
                st.write("ë‹¨ì  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
        st.markdown("---")
        st.markdown("### ğŸ”¤ í‚¤ì›Œë“œ ë¶„ì„")
        display_wordclouds(final_state["pros"], final_state["cons"])
        
        # ì‹œê°„ë³„ íŠ¸ë Œë“œ ì°¨íŠ¸
        st.markdown("---")
        st.markdown("### ğŸ“Š ë¦¬ë·° íŠ¸ë Œë“œ")
        
        # íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„± ë° í‘œì‹œ
        trend_chart = create_trend_chart(final_state.get("sources", []))
        if trend_chart:
            st.plotly_chart(trend_chart, use_container_width=True)
            
            # íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("""
                <div style="background: #e3f2fd; padding: 1rem; border-radius: 10px; text-align: center;">
                    <i class="fas fa-chart-line" style="font-size: 2rem; color: #1976d2;"></i>
                    <h5 style="margin: 0.5rem 0;">ë¦¬ë·° ì¶”ì´</h5>
                    <p style="margin: 0; font-size: 0.9rem;">ìµœê·¼ 6ê°œì›”ê°„ ë¦¬ë·° ë™í–¥</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown("""
                <div style="background: #f3e5f5; padding: 1rem; border-radius: 10px; text-align: center;">
                    <i class="fas fa-fire" style="font-size: 2rem; color: #7b1fa2;"></i>
                    <h5 style="margin: 0.5rem 0;">ì¸ê¸°ë„ ë³€í™”</h5>
                    <p style="margin: 0; font-size: 0.9rem;">ì œí’ˆ ê´€ì‹¬ë„ ì¶”ì´ ë¶„ì„</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown("""
                <div style="background: #e8f5e9; padding: 1rem; border-radius: 10px; text-align: center;">
                    <i class="fas fa-calendar-check" style="font-size: 2rem; color: #388e3c;"></i>
                    <h5 style="margin: 0.5rem 0;">ìµœì‹ ì„±</h5>
                    <p style="margin: 0; font-size: 0.9rem;">ìµœì‹  ë¦¬ë·° ê¸°ë°˜ ë¶„ì„</p>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.info("ì‹œê°„ë³„ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # ì¶œì²˜ (ì›¹ í¬ë¡¤ë§ì¸ ê²½ìš°)
        if final_state["sources"]:
            with st.expander("ğŸ“š ì¶œì²˜ ë³´ê¸°"):
                for idx, source in enumerate(final_state["sources"], 1):
                    st.markdown(f"""
                    <div style="padding: 0.5rem; margin: 0.3rem 0;">
                        <i class="fas fa-link"></i> {idx}. 
                        <a href="{source['link']}" target="_blank" style="color: {secondary_text};">
                            {source['title']}
                        </a>
                    </div>
                    """, unsafe_allow_html=True)
        
        # í†µê³„ ì¹´ë“œ
        st.markdown("---")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown("""
            <div class="metric-card">
                <i class="fas fa-thumbs-up" style="font-size: 2rem; color: #28a745;"></i>
                <h3 style="margin: 0.5rem 0;">{}</h3>
                <p style="margin: 0; opacity: 0.7;">ì´ ì¥ì </p>
            </div>
            """.format(len(final_state['pros'])), unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card">
                <i class="fas fa-thumbs-down" style="font-size: 2rem; color: #dc3545;"></i>
                <h3 style="margin: 0.5rem 0;">{}</h3>
                <p style="margin: 0; opacity: 0.7;">ì´ ë‹¨ì </p>
            </div>
            """.format(len(final_state['cons'])), unsafe_allow_html=True)
        
        with col3:
            icon = "fa-database" if final_state["search_method"] == "database" else "fa-globe"
            st.markdown("""
            <div class="metric-card">
                <i class="fas {}" style="font-size: 2rem; color: #2196f3;"></i>
                <h3 style="margin: 0.5rem 0;">{}</h3>
                <p style="margin: 0; opacity: 0.7;">ê²€ìƒ‰ ë°©ë²•</p>
            </div>
            """.format(icon, "DB" if final_state["search_method"] == "database" else "ì›¹"), unsafe_allow_html=True)
        
        with col4:
            total_score = len(final_state['pros']) / (len(final_state['pros']) + len(final_state['cons'])) * 100 if (len(final_state['pros']) + len(final_state['cons'])) > 0 else 0
            st.markdown("""
            <div class="metric-card">
                <i class="fas fa-star" style="font-size: 2rem; color: #ffc107;"></i>
                <h3 style="margin: 0.5rem 0;">{:.0f}%</h3>
                <p style="margin: 0; opacity: 0.7;">ê¸ì • ë¹„ìœ¨</p>
            </div>
            """.format(total_score), unsafe_allow_html=True)
        
        # ê³µìœ  ë²„íŠ¼
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            share_text = f"{product_name} ë¶„ì„ ê²°ê³¼: ì¥ì  {len(final_state['pros'])}ê°œ, ë‹¨ì  {len(final_state['cons'])}ê°œ"
            st.markdown(f"""
            <div style="text-align: center;">
                <a href="https://twitter.com/intent/tweet?text={share_text}" target="_blank" 
                   style="margin: 0 10px; color: #1DA1F2;">
                    <i class="fab fa-twitter" style="font-size: 1.5rem;"></i>
                </a>
                <a href="https://www.facebook.com/sharer/sharer.php?u=#" target="_blank" 
                   style="margin: 0 10px; color: #4267B2;">
                    <i class="fab fa-facebook" style="font-size: 1.5rem;"></i>
                </a>
                <button onclick="navigator.clipboard.writeText('{share_text}')" 
                        style="margin: 0 10px; background: none; border: none; cursor: pointer;">
                    <i class="fas fa-link" style="font-size: 1.5rem; color: #666;"></i>
                </button>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.error(f"'{product_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("""
    <div class="metric-card">
        <i class="fas fa-brain" style="color: #667eea;"></i>
        <p>LangGraphë¡œ êµ¬í˜„ëœ<br>ì²´ê³„ì ì¸ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤</p>
    </div>
    """, unsafe_allow_html=True)
with col2:
    st.markdown("""
    <div class="metric-card">
        <i class="fas fa-sync-alt" style="color: #28a745;"></i>
        <p>DB ìš°ì„  ê²€ìƒ‰<br>â†’ ì—†ìœ¼ë©´ ì›¹ í¬ë¡¤ë§</p>
    </div>
    """, unsafe_allow_html=True)
with col3:
    st.markdown("""
    <div class="metric-card">
        <i class="fas fa-save" style="color: #dc3545;"></i>
        <p>ê²€ìƒ‰ ê²°ê³¼<br>ìë™ ì €ì¥</p>
    </div>
    """, unsafe_allow_html=True)

current_date = datetime.now().strftime('%Yë…„ %mì›” %dì¼')
st.markdown(f"""
<div style="text-align: center; color: #666; padding: 2rem; margin-top: 2rem;">
    <p style="margin-bottom: 0.5rem;">
        <i class="fas fa-clock"></i> ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {current_date}
    </p>
    <p style="font-size: 0.9rem; opacity: 0.8;">
        Powered by LangGraph & OpenAI | Made with <i class="fas fa-heart" style="color: #e74c3c;"></i> by Smart Shopping Team
    </p>
</div>
""", unsafe_allow_html=True)
