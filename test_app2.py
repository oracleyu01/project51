

import streamlit as st

# í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ì²« ë²ˆì§¸ë¡œ ì‹¤í–‰)
st.set_page_config(
    page_title="ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸ (LangGraph)",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="expanded"
)

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import pandas as pd
from supabase import create_client
from openai import OpenAI
import os
from dotenv import load_dotenv
from datetime import datetime
import time
import json
import re
import requests
from bs4 import BeautifulSoup
import numpy as np
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import io
import base64
import urllib.request
import urllib.parse

# LangGraph ê´€ë ¨
from typing import TypedDict, Annotated, List, Union, Dict
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage
import operator

# ì•± ì‹œì‘ ì‹œ í°íŠ¸ ìë™ ë‹¤ìš´ë¡œë“œ
@st.cache_resource
def ensure_font():
    """í°íŠ¸ íŒŒì¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ"""
    font_path = "./NanumGothic.ttf"
    
    if not os.path.exists(font_path):
        with st.spinner("í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘..."):
            try:
                # ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ë‹¤ìš´ë¡œë“œ (ê³µì‹ GitHub ì €ì¥ì†Œ)
                url = "https://github.com/naver/nanumfont/raw/master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf"
                urllib.request.urlretrieve(url, font_path)
                st.success("âœ… í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"âŒ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # ëŒ€ì²´ URL ì‹œë„
                try:
                    alt_url = "https://cdn.jsdelivr.net/gh/naver/nanumfont@master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf"
                    urllib.request.urlretrieve(alt_url, font_path)
                    st.success("âœ… í•œê¸€ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! (ëŒ€ì²´ ê²½ë¡œ)")
                except:
                    st.warning("âš ï¸ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. í‚¤ì›Œë“œê°€ ì˜ë¬¸ìœ¼ë¡œ í‘œì‹œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    return None
    
    return font_path

# í°íŠ¸ í™•ì¸ (í˜ì´ì§€ ì„¤ì • í›„ ì‹¤í–‰)
font_path = ensure_font()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ ì„¤ì •
SUPABASE_URL = os.getenv("SUPABASE_URL") or st.secrets.get("SUPABASE_URL", "")
SUPABASE_KEY = os.getenv("SUPABASE_KEY") or st.secrets.get("SUPABASE_KEY", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", "")
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID") or st.secrets.get("NAVER_CLIENT_ID", "")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET") or st.secrets.get("NAVER_CLIENT_SECRET", "")

# LangSmith ì„¤ì • (ì„ íƒì )
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY") or st.secrets.get("LANGSMITH_API_KEY", "")
if LANGSMITH_API_KEY:
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_PROJECT"] = "career-insight-app"
    os.environ["LANGCHAIN_API_KEY"] = LANGSMITH_API_KEY
else:
    os.environ["LANGCHAIN_TRACING_V2"] = "false"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'dark_mode' not in st.session_state:
    st.session_state.dark_mode = False
if 'bookmarks' not in st.session_state:
    st.session_state.bookmarks = []
if 'search_history' not in st.session_state:
    st.session_state.search_history = []
if 'total_searches' not in st.session_state:
    st.session_state.total_searches = 0
if 'saved_careers' not in st.session_state:
    st.session_state.saved_careers = 0

# CSS ìŠ¤íƒ€ì¼ - ë‹¤í¬ëª¨ë“œ ì§€ì›
if st.session_state.dark_mode:
    bg_gradient = "linear-gradient(135deg, #1a1a2e 0%, #16213e 100%)"
    card_bg = "#0f3460"
    text_color = "#ffffff"
    secondary_text = "#e94560"
    header_gradient = "linear-gradient(135deg, #e94560 0%, #0f3460 100%)"
else:
    bg_gradient = "linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%)"
    card_bg = "white"
    text_color = "#333333"
    secondary_text = "#667eea"
    header_gradient = "linear-gradient(135deg, #667eea 0%, #764ba2 100%)"

st.markdown(f"""
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
<style>
    /* ì „ì²´ ë°°ê²½ ë° ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
    .stApp {{
        background: {bg_gradient};
    }}
    
    /* ë©”ì¸ í—¤ë” ê°œì„  */
    .main-header {{
        text-align: center;
        padding: 3rem 0;
        background: {header_gradient};
        color: white;
        border-radius: 20px;
        margin-bottom: 3rem;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        position: relative;
        overflow: hidden;
    }}
    
    .main-header h1 {{
        text-shadow: 3px 3px 6px rgba(0, 0, 0, 0.3), 
                     0 0 20px rgba(255, 255, 255, 0.2);
    }}
    
    .main-header p {{
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
    }}
    
    .main-header::before {{
        content: "";
        position: absolute;
        top: -50%;
        right: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: shimmer 3s infinite;
    }}
    
    @keyframes shimmer {{
        0% {{ transform: rotate(0deg); }}
        100% {{ transform: rotate(360deg); }}
    }}
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .search-card {{
        background: {card_bg};
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 5px 20px rgba(0, 0, 0, 0.08);
        margin-bottom: 2rem;
        color: {text_color};
    }}
    
    /* ì¥ì  ì„¹ì…˜ ê°œì„  */
    .pros-section {{
        background: linear-gradient(135deg, #d4f1d4 0%, #b8e6b8 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(40, 167, 69, 0.1);
        transition: transform 0.3s ease;
    }}
    
    .pros-section:hover {{
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(40, 167, 69, 0.15);
    }}
    
    /* ë‹¨ì  ì„¹ì…˜ ê°œì„  */
    .cons-section {{
        background: linear-gradient(135deg, #ffd6d6 0%, #ffb8b8 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(220, 53, 69, 0.1);
        transition: transform 0.3s ease;
    }}
    
    .cons-section:hover {{
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(220, 53, 69, 0.15);
    }}
    
    /* í”„ë¡œì„¸ìŠ¤ ì •ë³´ ê°œì„  */
    .process-info {{
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1.5rem 0;
        border: none;
        box-shadow: 0 3px 10px rgba(33, 150, 243, 0.1);
    }}
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stButton > button {{
        background: {header_gradient};
        color: white;
        border: none;
        padding: 0.75rem 2rem;
        border-radius: 30px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }}
    
    .stButton > button:hover {{
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
    }}
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input {{
        border-radius: 10px;
        border: 2px solid #e0e0e0;
        padding: 0.75rem 1rem;
        transition: all 0.3s ease;
        background: {card_bg};
        color: {text_color};
    }}
    
    .stTextInput > div > div > input:focus {{
        border-color: {secondary_text};
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }}
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .metric-card {{
        background: {card_bg};
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 3px 10px rgba(0, 0, 0, 0.08);
        text-align: center;
        transition: all 0.3s ease;
        color: {text_color};
    }}
    
    .metric-card:hover {{
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.12);
    }}
    
    /* ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ */
    @keyframes fadeIn {{
        from {{ opacity: 0; transform: translateY(20px); }}
        to {{ opacity: 1; transform: translateY(0); }}
    }}
    
    .fade-in {{
        animation: fadeIn 0.6s ease-out;
    }}
    
    /* ë¡œë”© ìŠ¤í”¼ë„ˆ */
    .spinner {{
        width: 50px;
        height: 50px;
        margin: 0 auto;
        border: 5px solid #f3f3f3;
        border-top: 5px solid {secondary_text};
        border-radius: 50%;
        animation: spin 1s linear infinite;
    }}
    
    @keyframes spin {{
        0% {{ transform: rotate(0deg); }}
        100% {{ transform: rotate(360deg); }}
    }}
    
    /* í”„ë¡œìŠ¤/ì½˜ìŠ¤ ì•„ì´í…œ */
    .pros-item, .cons-item {{
        background: white;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 8px;
        transition: all 0.3s ease;
        animation: fadeIn 0.5s ease-out;
    }}
    
    .pros-item {{
        border-left: 4px solid #28a745;
    }}
    
    .cons-item {{
        border-left: 4px solid #dc3545;
    }}
    
    .pros-item:hover, .cons-item:hover {{
        transform: translateX(5px);
        box-shadow: 0 3px 10px rgba(0, 0, 0, 0.1);
    }}
    
    /* ëª¨ë°”ì¼ ë°˜ì‘í˜• */
    @media (max-width: 768px) {{
        .main-header {{
            padding: 2rem 1rem;
            font-size: 0.9rem;
        }}
        .main-header h1 {{
            font-size: 1.8rem;
        }}
        .search-card {{
            padding: 1.5rem 1rem;
        }}
        .pros-section, .cons-section {{
            padding: 1.5rem 1rem;
        }}
    }}
    
    /* í”„ë¡œê·¸ë ˆìŠ¤ ë°” */
    .progress-bar {{
        width: 100%;
        height: 8px;
        background-color: #e0e0e0;
        border-radius: 4px;
        overflow: hidden;
        margin: 1rem 0;
    }}
    
    .progress-fill {{
        height: 100%;
        background: {header_gradient};
        animation: progress 2s ease-out;
    }}
    
    @keyframes progress {{
        from {{ width: 0%; }}
        to {{ width: 100%; }}
    }}
    
    /* ê²€ìƒ‰ ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
    .search-section {{
        margin-top: -3rem;
        padding: 1rem 0 2rem 0;
    }}
    
    .search-title {{
        text-align: center;
        color: {text_color};
        margin-bottom: 1.5rem;
        margin-top: -1rem;
        font-size: 2.5rem;
        font-weight: 700;
        letter-spacing: -0.5px;
    }}
    
    /* ê²€ìƒ‰ ì…ë ¥ì°½ í¬ê¸° ëŒ€í­ í™•ëŒ€ ë° êµµì€ ê¸€ì”¨ */
    .big-search .stTextInput > div > div > input {{
        height: 100px !important;
        font-size: 2.2rem !important;
        font-weight: 700 !important;
        padding: 2rem 3.5rem !important;
        border-radius: 50px !important;
        border: 4px solid #e0e0e0 !important;
        transition: all 0.3s ease !important;
        text-align: center !important;
        letter-spacing: 1px !important;
        line-height: 1.2 !important;
    }}
    
    .big-search .stTextInput > div > div > input:focus {{
        border-color: {secondary_text} !important;
        box-shadow: 0 0 0 8px rgba(102, 126, 234, 0.15) !important;
        transform: translateY(-2px) !important;
        border-width: 4px !important;
    }}
    
    /* í”Œë ˆì´ìŠ¤í™€ë” ìŠ¤íƒ€ì¼ */
    .big-search .stTextInput > div > div > input::placeholder {{
        color: #aaa !important;
        font-size: 1.5rem !important;
        text-align: center !important;
        font-weight: 400 !important;
        opacity: 0.7 !important;
    }}
    
    /* ë²„íŠ¼ í¬ê¸° ì¡°ì • */
    .search-buttons .stButton > button {{
        height: 60px !important;
        font-size: 1.4rem !important;
        padding: 0 3.5rem !important;
        font-weight: 700 !important;
        letter-spacing: 0.5px !important;
    }}
    
    /* ì¸ê¸° ê²€ìƒ‰ì–´ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .popular-search-buttons .stButton > button {{
        height: 45px !important;
        font-size: 1.1rem !important;
        font-weight: 500 !important;
    }}
    
    /* ì§ì—… ê´€ë ¨ ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
    .career-insight {{
        background: linear-gradient(135deg, #f0f4ff 0%, #e0e7ff 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.1);
    }}
    
    .salary-section {{
        background: linear-gradient(135deg, #fff9e6 0%, #ffe5b4 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(255, 193, 7, 0.1);
    }}
    
    .career-path {{
        background: linear-gradient(135deg, #e6f3ff 0%, #c5e0ff 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border: none;
        box-shadow: 0 5px 15px rgba(33, 150, 243, 0.1);
    }}
    
    /* ì±„ìš© ê³µê³  ì¹´ë“œ í˜¸ë²„ íš¨ê³¼ */
    .job-posting-card {{
        transition: all 0.3s ease;
        cursor: pointer;
    }}
    
    .job-posting-card:hover {{
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }}
    
    /* ì§€ì›í•˜ê¸° ë²„íŠ¼ í˜¸ë²„ íš¨ê³¼ */
    .apply-button {{
        transition: all 0.3s ease;
    }}
    
    .apply-button:hover {{
        transform: translateX(5px);
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
    }}
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    dark_mode = st.checkbox("ğŸŒ™ ë‹¤í¬ëª¨ë“œ", value=st.session_state.dark_mode)
    st.session_state.dark_mode = dark_mode
    
    st.markdown("### ğŸ“Œ ë¶ë§ˆí¬")
    if st.session_state.bookmarks:
        for bookmark in st.session_state.bookmarks:
            if st.button(f"ğŸ”– {bookmark}", key=f"bookmark_{bookmark}"):
                st.session_state.selected_bookmark = bookmark
    else:
        st.info("ë¶ë§ˆí¬ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    st.markdown("### ğŸ“Š ì‚¬ìš© í†µê³„")
    st.metric("ì´ ê²€ìƒ‰ ìˆ˜", f"{st.session_state.total_searches}íšŒ")
    st.metric("ì €ì¥ëœ ì§ì—…", f"{st.session_state.saved_careers}ê°œ")

# í—¤ë” - ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸
st.markdown("""
<div class="main-header">
    <h1 style="margin-bottom: 0.5rem;">ğŸ’¼ ì»¤ë¦¬ì–´ ì¸ì‚¬ì´íŠ¸ (LangGraph Edition)</h1>
    <p style="font-size: 1.2rem; margin-top: 0.5rem;">
        LangGraphë¡œ êµ¬í˜„í•œ ì§€ëŠ¥í˜• ì§ì—… ì¥ë‹¨ì  ë¶„ì„ ì‹œìŠ¤í…œ
    </p>
    <p style="font-size: 0.9rem; margin-top: 0.3rem; opacity: 0.8;">
        <i class="fas fa-robot"></i> AIê°€ ë‹¤ì–‘í•œ ì§ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í˜„ì‹¤ì ì¸ ì¥ë‹¨ì ì„ ì œê³µí•©ë‹ˆë‹¤
    </p>
</div>
""", unsafe_allow_html=True)

# ========================
# LangGraph State ì •ì˜
# ========================

class CareerState(TypedDict):
    """ì§ì—… ë¶„ì„ í”„ë¡œì„¸ìŠ¤ì˜ ìƒíƒœ"""
    career_name: str
    search_method: str  # "database" or "web_crawling"
    results: dict
    pros: List[str]
    cons: List[str]
    sources: List[dict]
    salary_info: dict
    career_path: List[str]
    job_postings: List[dict]  # ì±„ìš© ê³µê³  ì¶”ê°€
    messages: Annotated[List[Union[HumanMessage, AIMessage]], operator.add]
    error: str

# ========================
# í¬ë¡¤ë§ í´ë˜ìŠ¤
# ========================

class CareerInfoCrawler:
    def __init__(self, naver_client_id, naver_client_secret):
        self.naver_headers = {
            "X-Naver-Client-Id": naver_client_id,
            "X-Naver-Client-Secret": naver_client_secret
        }
        self.openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
        
        # í†µê³„
        self.stats = {
            'total_crawled': 0,
            'valid_pros_cons': 0,
            'api_errors': 0
        }
    
    def remove_html_tags(self, text):
        """HTML íƒœê·¸ ì œê±°"""
        text = BeautifulSoup(text, "html.parser").get_text()
        text = re.sub(r'<[^>]+>', '', text)
        return text.strip()
    
    def search_career_info(self, query, display=20):
        """ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ í†µí•´ ì§ì—… ì •ë³´ ê²€ìƒ‰"""
        url = "https://openapi.naver.com/v1/search/blog"
        
        # ì§ì—… ê´€ë ¨ ê²€ìƒ‰ì–´ ì¡°í•©
        search_queries = [
            f"{query} ì§ì—… ì¥ë‹¨ì ",
            f"{query} í˜„ì‹¤ ë‹¨ì ",
            f"{query} ì‹¤ì œ ì¥ì ",
            f"{query} ì—°ë´‰ ì›Œë¼ë°¸",
            f"{query} ì§ì—… í›„ê¸°"
        ]
        
        all_results = []
        
        for search_query in search_queries:
            params = {
                "query": search_query,
                "display": 10,
                "sort": "sim"
            },
            "ìë°” ê°œë°œì": {
                "pros": [
                    "ì•ˆì •ì ì¸ ê¸°ìˆ  ìŠ¤íƒ",
                    "ëŒ€ê¸°ì—…ê³¼ ê¸ˆìœµê¶Œ ìˆ˜ìš” ë†’ìŒ",
                    "ì²´ê³„ì ì¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤",
                    "í’ë¶€í•œ ë ˆí¼ëŸ°ìŠ¤ì™€ ì»¤ë®¤ë‹ˆí‹°",
                    "Spring ìƒíƒœê³„ì˜ ê°•ë ¥í•¨"
                ],
                "cons": [
                    "ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜",
                    "ë³´ìˆ˜ì ì¸ ê¸°ìˆ  í™˜ê²½",
                    "ê¸´ ë¹Œë“œ ì‹œê°„",
                    "ë¬´ê±°ìš´ í”„ë ˆì„ì›Œí¬",
                    "ìµœì‹  ê¸°ìˆ  ë„ì… ì–´ë ¤ì›€"
                ]
            },
            "DBA": {
                "pros": [
                    "ì•ˆì •ì ì¸ ì§ë¬´ë¡œ ìˆ˜ìš”ê°€ ê¾¸ì¤€í•¨",
                    "ê¸°ìˆ ì˜ ë³€í™”ê°€ ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼",
                    "ë†’ì€ ì „ë¬¸ì„±ìœ¼ë¡œ ëŒ€ì²´ ë¶ˆê°€ëŠ¥",
                    "ì²´ê³„ì ì¸ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤",
                    "ê¸ˆìœµ, ëŒ€ê¸°ì—… ë“± ì•ˆì •ì ì¸ ì§ì¥"
                ],
                "cons": [
                    "24ì‹œê°„ ì˜¨ì½œ ëŒ€ì‘ ë¶€ë‹´",
                    "ì¥ì•  ë°œìƒ ì‹œ í° ì±…ì„ê°",
                    "ë°˜ë³µì ì¸ ëª¨ë‹ˆí„°ë§ ì—…ë¬´",
                    "ìƒˆë¡œìš´ ê¸°ìˆ  ë„ì…ì´ ë³´ìˆ˜ì ",
                    "ì•¼ê°„ ì‘ì—…ì´ ì¦ìŒ"
                ]
            },
            "DB ì—”ì§€ë‹ˆì–´": {
                "pros": [
                    "ë°ì´í„° ëª¨ë¸ë§ì˜ ì°½ì˜ì„±",
                    "ì„±ëŠ¥ íŠœë‹ì˜ ì„±ì·¨ê°",
                    "ê°œë°œê³¼ ìš´ì˜ì˜ ê· í˜•ì¡íŒ ì—­í• ",
                    "ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ ê²½í—˜ ê°€ëŠ¥",
                    "ë°±ì—”ë“œ ê°œë°œë¡œ ì „í™˜ ìš©ì´"
                ],
                "cons": [
                    "ë³µì¡í•œ ì¿¼ë¦¬ ìµœì í™” ì••ë°•",
                    "ë ˆê±°ì‹œ DB ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤íŠ¸ë ˆìŠ¤",
                    "ë‹¤ì–‘í•œ DBMS í•™ìŠµ ë¶€ë‹´",
                    "ê°œë°œíŒ€ê³¼ ìš´ì˜íŒ€ ì‚¬ì´ì˜ ê°ˆë“±",
                    "ì„±ëŠ¥ ì´ìŠˆì— ëŒ€í•œ ì±…ì„"
                ]
            },
            "AI ì—”ì§€ë‹ˆì–´": {
                "pros": [
                    "ìµœì‹  ê¸°ìˆ ì„ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©",
                    "ë†’ì€ ì—°ë´‰ê³¼ ëŒ€ìš°",
                    "MLOps ë¶„ì•¼ì˜ ì„±ì¥ ê°€ëŠ¥ì„±",
                    "ë‹¤ì–‘í•œ AI ëª¨ë¸ ê²½í—˜",
                    "ê¸€ë¡œë²Œ ê¸°ì—… ì§„ì¶œ ê¸°íšŒ"
                ],
                "cons": [
                    "ë³µì¡í•œ ì¸í”„ë¼ ê´€ë¦¬",
                    "ë†’ì€ ì»´í“¨íŒ… ë¹„ìš© ë¶€ë‹´",
                    "ëª¨ë¸ê³¼ ì‹œìŠ¤í…œ ì–‘ìª½ ì§€ì‹ í•„ìš”",
                    "ì‹¤ì‹œê°„ ì„œë¹™ì˜ ê¸°ìˆ ì  ë‚œì´ë„",
                    "ë¹ ë¥¸ ê¸°ìˆ  ë³€í™” ì†ë„"
                ]
            }
            
            try:
                response = requests.get(url, headers=self.naver_headers, params=params)
                if response.status_code == 200:
                    result = response.json()
                    for item in result.get('items', []):
                        item['title'] = self.remove_html_tags(item['title'])
                        item['description'] = self.remove_html_tags(item['description'])
                    all_results.extend(result.get('items', []))
            except Exception as e:
                print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return all_results
    
    def crawl_content(self, url):
        """ë¸”ë¡œê·¸ ë³¸ë¬¸ í¬ë¡¤ë§"""
        try:
            if "blog.naver.com" in url:
                parts = url.split('/')
                if len(parts) >= 5:
                    blog_id = parts[3]
                    post_no = parts[4].split('?')[0]
                    mobile_url = f"https://m.blog.naver.com/{blog_id}/{post_no}"
                    
                    response = requests.get(mobile_url, headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    })
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.content, 'html.parser')
                        
                        content = ""
                        for selector in ['div.se-main-container', 'div#postViewArea', 'div.post_ct']:
                            elem = soup.select_one(selector)
                            if elem:
                                content = elem.get_text(separator='\n', strip=True)
                                break
                        
                        if not content:
                            content = soup.get_text(separator='\n', strip=True)
                        
                        content = re.sub(r'\s+', ' ', content)
                        content = content.replace('\u200b', '')
                        
                        return content if len(content) > 300 else None
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return None
    
    def extract_career_pros_cons_with_gpt(self, career_name, content):
        """ChatGPTë¡œ ì§ì—… ì¥ë‹¨ì  ì¶”ì¶œ"""
        if not content or len(content) < 200 or not self.openai_client:
            return None
        
        content_preview = content[:2000]
        
        prompt = f"""ë‹¤ìŒì€ "{career_name}" ì§ì—…ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ì…ë‹ˆë‹¤.

[ë¸”ë¡œê·¸ ë‚´ìš©]
{content_preview}

ìœ„ ë‚´ìš©ì—ì„œ {career_name} ì§ì—…ì˜ í˜„ì‹¤ì ì¸ ì¥ì ê³¼ ë‹¨ì ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ì‹¤ì œ ê²½í—˜ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ë‚´ìš©ë§Œ í¬í•¨í•˜ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ì¥ì :
- (êµ¬ì²´ì ì¸ ì¥ì  1)
- (êµ¬ì²´ì ì¸ ì¥ì  2)
- (êµ¬ì²´ì ì¸ ì¥ì  3)

ë‹¨ì :
- (êµ¬ì²´ì ì¸ ë‹¨ì  1)
- (êµ¬ì²´ì ì¸ ë‹¨ì  2)
- (êµ¬ì²´ì ì¸ ë‹¨ì  3)

ë§Œì•½ ì¥ë‹¨ì  ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ "ì •ë³´ ë¶€ì¡±"ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”."""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì§ì—… ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê° ì§ì—…ì˜ í˜„ì‹¤ì ì¸ ì¥ë‹¨ì ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            result = response.choices[0].message.content.strip()
            
            if result and "ì •ë³´ ë¶€ì¡±" not in result:
                pros = []
                cons = []
                
                lines = result.split('\n')
                current_section = None
                
                for line in lines:
                    line = line.strip()
                    if 'ì¥ì :' in line or 'ì¥ì  :' in line:
                        current_section = 'pros'
                    elif 'ë‹¨ì :' in line or 'ë‹¨ì  :' in line:
                        current_section = 'cons'
                    elif line.startswith('-') and current_section:
                        point = line[1:].strip()
                        if point and len(point) > 5:
                            if current_section == 'pros':
                                pros.append(point)
                            else:
                                cons.append(point)
                
                if pros or cons:
                    self.stats['valid_pros_cons'] += 1
                    return {
                        'pros': pros[:5],
                        'cons': cons[:5]
                    }
            
            return None
                
        except Exception as e:
            self.stats['api_errors'] += 1
            print(f"GPT API ì˜¤ë¥˜: {str(e)[:100]}")
            return None
    
    def deduplicate_points(self, points):
        """ìœ ì‚¬í•œ ì¥ë‹¨ì  ì¤‘ë³µ ì œê±°"""
        if not points:
            return []
        
        unique_points = []
        seen_keywords = set()
        
        for point in points:
            keywords = set(word for word in point.split() if len(word) > 2)
            
            if len(keywords & seen_keywords) < len(keywords) * 0.5:
                unique_points.append(point)
                seen_keywords.update(keywords)
            
            if len(unique_points) >= 10:
                break
        
        return unique_points
    
    def get_career_salary_info(self, career_name):
        """ì§ì—… ì—°ë´‰ ì •ë³´ ì¶”ì¶œ (ìƒ˜í”Œ)"""
        # ì‹¤ì œë¡œëŠ” APIë‚˜ í¬ë¡¤ë§ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„° ì œê³µ
        sample_salaries = {
            "ë°ì´í„° ë¶„ì„ê°€": {"min": 4000, "avg": 6000, "max": 9000},
            "ë°ì´í„° ì—”ì§€ë‹ˆì–´": {"min": 5000, "avg": 7500, "max": 12000},
            "DBA": {"min": 4500, "avg": 7000, "max": 11000},
            "DB ì—”ì§€ë‹ˆì–´": {"min": 4500, "avg": 6500, "max": 10000},
            "AI ê°œë°œì": {"min": 5500, "avg": 8000, "max": 15000},
            "AI ì—”ì§€ë‹ˆì–´": {"min": 6000, "avg": 9000, "max": 18000            },
            "ë°ì´í„° ì—”ì§€ë‹ˆì–´": {
                "pros": [
                    "ë†’ì€ ìˆ˜ìš”ì™€ ì¢‹ì€ ì²˜ìš°",
                    "ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ì˜ ì„±ì·¨ê°",
                    "í´ë¼ìš°ë“œ ê¸°ìˆ  ì „ë¬¸ì„± í™•ë³´",
                    "ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì˜ í•µì‹¬ ì—­í• ",
                    "ë‹¤ì–‘í•œ ë„ë©”ì¸ ê²½í—˜ ê°€ëŠ¥"
                ],
                "cons": [
                    "24/7 íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§",
                    "ë³µì¡í•œ ê¸°ìˆ  ìŠ¤íƒ ê´€ë¦¬",
                    "ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ëŒ€ì‘",
                    "ê°€ì‹œì  ì„±ê³¼ ë¶€ì¡±",
                    "ì§€ì†ì ì¸ ìµœì í™” ì••ë°•"
                ]
            },
            "ìë°” ê°œë°œì": {"min": 4000, "avg": 6000, "max": 10000},
            "ë°±ì—”ë“œ ê°œë°œì": {"min": 4500, "avg": 6500, "max": 11000}
        }
        
        # ê¸°ë³¸ê°’
        default_salary = {"min": 4000, "avg": 6000, "max": 9000}
        
        for key, value in sample_salaries.items():
            if key in career_name:
                return value
        
        return default_salary
    
    def get_realtime_job_postings(self, career_name):
        """ì‹¤ì‹œê°„ ì±„ìš© ê³µê³  í¬ë¡¤ë§"""
        import urllib.parse
        
        # ê²€ìƒ‰ì–´ ìƒì„± (ì‹ ì…, ê²½ë ¥ 1-2ë…„)
        search_keywords = [
            f"{career_name} ì‹ ì…",
            f"{career_name} ì£¼ë‹ˆì–´",
            f"{career_name} ê²½ë ¥ 1ë…„",
            f"{career_name} ê²½ë ¥ 2ë…„"
        ]
        
        all_postings = []
        
        try:
            # ë„¤ì´ë²„ ê²€ìƒ‰ìœ¼ë¡œ ì±„ìš© ì •ë³´ ìˆ˜ì§‘
            for keyword in search_keywords[:2]:  # API í˜¸ì¶œ ì œí•œìœ¼ë¡œ 2ê°œë§Œ
                encoded_query = urllib.parse.quote(f"{keyword} ì±„ìš©")
                url = "https://openapi.naver.com/v1/search/webkr.json"
                
                params = {
                    "query": encoded_query,
                    "display": 10,
                    "sort": "date"  # ìµœì‹ ìˆœ
                }
                
                response = requests.get(url, headers=self.naver_headers, params=params)
                
                if response.status_code == 200:
                    results = response.json()
                    
                    for item in results.get('items', []):
                        title = self.remove_html_tags(item.get('title', ''))
                        description = self.remove_html_tags(item.get('description', ''))
                        link = item.get('link', '')
                        
                        # ì±„ìš© ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
                        if any(word in title + description for word in ['ì±„ìš©', 'ëª¨ì§‘', 'êµ¬ì¸', 'hiring', 'recruit']):
                            # íšŒì‚¬ëª… ì¶”ì¶œ ì‹œë„
                            company = ""
                            for corp_indicator in ['(ì£¼)', 'ãˆœ', 'ì£¼ì‹íšŒì‚¬', 'Corp', 'Inc', 'Ltd']:
                                if corp_indicator in title:
                                    parts = title.split(corp_indicator)
                                    if parts:
                                        company = parts[0].strip() + corp_indicator
                                        break
                            
                            if not company:
                                # ì œëª©ì—ì„œ ì²« ë‹¨ì–´ë¥¼ íšŒì‚¬ëª…ìœ¼ë¡œ ì¶”ì •
                                company = title.split()[0] if title.split() else "ê¸°ì—…"
                            
                            # ì—°ë´‰ ì •ë³´ ì¶”ì¶œ ì‹œë„
                            salary = "íšŒì‚¬ ë‚´ê·œ"
                            salary_patterns = [
                                r'(\d{3,4})\s*ë§Œ\s*ì›',
                                r'(\d{3,4})\s*ë§Œì›',
                                r'(\d{3,4})\s*~\s*(\d{3,4})',
                                r'ì—°ë´‰\s*(\d{3,4})'
                            ]
                            
                            for pattern in salary_patterns:
                                match = re.search(pattern, description)
                                if match:
                                    if match.lastindex == 2:  # ë²”ìœ„ì¸ ê²½ìš°
                                        salary = f"{match.group(1)}~{match.group(2)}ë§Œì›"
                                    else:
                                        salary = f"{match.group(1)}ë§Œì›~"
                                    break
                            
                            # ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
                            location = "ì„œìš¸"
                            locations = ['ê°•ë‚¨', 'íŒêµ', 'ë¶„ë‹¹', 'ì—¬ì˜ë„', 'êµ¬ë¡œ', 'ê°€ì‚°', 'ìƒì•”', 'ì„ì§€ë¡œ', 'ì¢…ë¡œ', 'ë§ˆí¬']
                            for loc in locations:
                                if loc in description:
                                    location = loc
                                    break
                            
                            posting = {
                                "company": company[:20],  # íšŒì‚¬ëª… ê¸¸ì´ ì œí•œ
                                "title": title[:50],
                                "description": description[:200],
                                "link": link,
                                "salary": salary,
                                "location": location,
                                "type": "ì •ê·œì§",
                                "requirements": []
                            }
                            
                            # ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
                            req_keywords = ['ê²½í—˜', 'ëŠ¥ë ¥', 'ìš°ëŒ€', 'í•„ìˆ˜', 'ìê²©', 'ì¡°ê±´']
                            req_sentences = [sent for sent in description.split('.') 
                                           if any(kw in sent for kw in req_keywords)]
                            posting["requirements"] = req_sentences[:3]
                            
                            all_postings.append(posting)
                
                time.sleep(0.5)  # API í˜¸ì¶œ ì œí•œ
                
        except Exception as e:
            print(f"ì±„ìš© ì •ë³´ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        seen_companies = set()
        unique_postings = []
        for posting in all_postings:
            if posting["company"] not in seen_companies and len(unique_postings) < 5:
                seen_companies.add(posting["company"])
                unique_postings.append(posting)
        
        return unique_postings

# ========================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ========================

def show_loading_animation():
    """ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ í‘œì‹œ"""
    loading_placeholder = st.empty()
    loading_placeholder.markdown("""
    <div style="text-align: center; padding: 3rem;">
        <div class="spinner"></div>
        <p style="margin-top: 1rem; color: #667eea; font-weight: 600;">
            <i class="fas fa-brain"></i> AIê°€ ì§ì—… ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...
        </p>
        <div class="progress-bar">
            <div class="progress-fill"></div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    return loading_placeholder

def create_pros_cons_chart(pros_count, cons_count):
    """ì¥ë‹¨ì  ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure(data=[
        go.Bar(
            name='ì¥ì ',
            x=['ë¶„ì„ ê²°ê³¼'],
            y=[pros_count],
            marker_color='#28a745',
            text=f'{pros_count}ê°œ',
            textposition='auto',
            hovertemplate='ì¥ì : %{y}ê°œ<extra></extra>'
        ),
        go.Bar(
            name='ë‹¨ì ',
            x=['ë¶„ì„ ê²°ê³¼'],
            y=[cons_count],
            marker_color='#dc3545',
            text=f'{cons_count}ê°œ',
            textposition='auto',
            hovertemplate='ë‹¨ì : %{y}ê°œ<extra></extra>'
        )
    ])
    
    fig.update_layout(
        barmode='group',
        height=300,
        margin=dict(l=0, r=0, t=30, b=0),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(size=14),
        showlegend=True,
        legend=dict(x=0.3, y=1.1, orientation='h'),
        xaxis=dict(showgrid=False, showticklabels=False),
        yaxis=dict(showgrid=True, gridcolor='rgba(0,0,0,0.1)'),
        bargap=0.3
    )
    
    return fig

def extract_keywords(texts):
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ì§ì—… ê´€ë ¨ ë¶ˆìš©ì–´
    stopwords = {
        'ìˆ˜', 'ìˆìŠµë‹ˆë‹¤', 'ìˆì–´ìš”', 'ìˆìŒ', 'ì¢‹ìŠµë‹ˆë‹¤', 'ì¢‹ì•„ìš”', 'ì¢‹ìŒ', 
        'ë‚˜ì©ë‹ˆë‹¤', 'ë‚˜ë¹ ìš”', 'ë‚˜ì¨', 'ì•ŠìŠµë‹ˆë‹¤', 'ì•Šì•„ìš”', 'ì•ŠìŒ',
        'ì…ë‹ˆë‹¤', 'ì´ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ê°™ë‹¤',
        'ì§ì—…', 'ì¼', 'ì—…ë¬´', 'ê·¼ë¬´', 'íšŒì‚¬', 'ì§ì¥', 'ë¶„ì•¼',
        'ìœ„í•´', 'í†µí•´', 'ëŒ€í•´', 'ë§¤ìš°', 'ì •ë§', 'ë„ˆë¬´', 'ì¡°ê¸ˆ',
        'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ¬ë‚˜', 'ë˜í•œ', 'ë•Œë¬¸', 'ê²½ìš°',
        'ì œê³µí•©ë‹ˆë‹¤', 'ì œê³µ', 'í•©ë‹ˆë‹¤', 'í•´ìš”', 'ë“œë¦½ë‹ˆë‹¤', 'ë“œë ¤ìš”'
    }
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•˜ê³  í‚¤ì›Œë“œ ì¶”ì¶œ
    all_text = ' '.join(texts)
    
    # í•œê¸€ë§Œ ì¶”ì¶œ
    words = re.findall(r'[ê°€-í£]+', all_text)
    
    # í•„í„°ë§
    filtered_words = []
    for word in words:
        if (len(word) >= 2 and 
            word not in stopwords and
            not word.endswith('ìŠµë‹ˆë‹¤') and
            not word.endswith('í•©ë‹ˆë‹¤')):
            filtered_words.append(word)
    
    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    word_freq = Counter(filtered_words)
    
    # ë¹ˆë„ìˆ˜ê°€ 1ì¸ ë‹¨ì–´ëŠ” ì œì™¸
    word_freq = {word: freq for word, freq in word_freq.items() if freq > 1}
    
    return word_freq

def create_wordcloud(texts, title, color_scheme):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not texts:
        return None
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    word_freq = extract_keywords(texts)
    
    if not word_freq:
        return None
    
    # ë¹ˆë„ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í‚¤ì›Œë“œë§Œ ì„ íƒ
    top_keywords = dict(sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:30])
    
    # matplotlib í•œê¸€ í°íŠ¸ ì„¤ì •
    font_path = "./NanumGothic.ttf"
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    plt.figure(figsize=(10, 6), facecolor='white')
    
    if font_path and os.path.exists(font_path) and top_keywords:
        try:
            wordcloud = WordCloud(
                width=800,
                height=400,
                background_color='white',
                colormap=color_scheme,
                font_path=font_path,
                relative_scaling=0.7,
                min_font_size=14,
                max_words=30,
                prefer_horizontal=0.8,
                margin=15,
                collocations=False
            ).generate_from_frequencies(top_keywords)
            
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.tight_layout(pad=0)
            
            # ì´ë¯¸ì§€ë¥¼ bytesë¡œ ë³€í™˜
            buf = io.BytesIO()
            plt.savefig(buf, format='png', dpi=150, bbox_inches='tight', facecolor='white', edgecolor='none')
            buf.seek(0)
            plt.close()
            
            return buf
            
        except Exception as e:
            plt.close()
            st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return None
    else:
        st.warning(f"í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

def display_wordclouds(pros, cons):
    """ì¥ë‹¨ì  ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ"""
    col1, col2 = st.columns(2)
    
    with col1:
        if pros:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #d4f1d4 0%, #b8e6b8 100%); border-radius: 15px;">
                <h3 style="color: #28a745; margin: 0;">
                    <i class="fas fa-check-circle"></i> ì¥ì  í‚¤ì›Œë“œ
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            pros_wordcloud = create_wordcloud(pros, "", "Greens")
            if pros_wordcloud:
                st.image(pros_wordcloud, use_container_width=True)
    
    with col2:
        if cons:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: linear-gradient(135deg, #ffd6d6 0%, #ffb8b8 100%); border-radius: 15px;">
                <h3 style="color: #dc3545; margin: 0;">
                    <i class="fas fa-times-circle"></i> ë‹¨ì  í‚¤ì›Œë“œ
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            cons_wordcloud = create_wordcloud(cons, "", "Reds")
            if cons_wordcloud:
                st.image(cons_wordcloud, use_container_width=True)

def create_salary_chart(salary_info, career_name):
    """ì—°ë´‰ ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # ë§‰ëŒ€ ê·¸ë˜í”„
    fig.add_trace(go.Bar(
        x=['ìµœì†Œ', 'í‰ê· ', 'ìµœëŒ€'],
        y=[salary_info['min'], salary_info['avg'], salary_info['max']],
        marker_color=['#dc3545', '#ffc107', '#28a745'],
        text=[f"{salary_info['min']:,}ë§Œì›", f"{salary_info['avg']:,}ë§Œì›", f"{salary_info['max']:,}ë§Œì›"],
        textposition='auto',
        hovertemplate='%{x}: %{text}<extra></extra>'
    ))
    
    fig.update_layout(
        title={
            'text': f'ğŸ’° {career_name} ì—°ë´‰ ë²”ìœ„',
            'font': {'size': 20},
            'x': 0.5,
            'xanchor': 'center'
        },
        height=400,
        margin=dict(l=0, r=0, t=50, b=0),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(size=14),
        showlegend=False,
        yaxis=dict(
            title='ì—°ë´‰ (ë§Œì›)',
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)'
        ),
        xaxis=dict(showgrid=False)
    )
    
    return fig

def create_career_path_timeline(career_path):
    """ê²½ë ¥ ê°œë°œ íƒ€ì„ë¼ì¸ ìƒì„±"""
    fig = go.Figure()
    
    # ê° ë‹¨ê³„ë³„ ì—°ì°¨ ì¶”ì • (IT ì§êµ° ê¸°ì¤€)
    years = [0, 2, 5, 8, 12, 15]
    
    # íƒ€ì„ë¼ì¸ ìƒì„±
    fig.add_trace(go.Scatter(
        x=years[:len(career_path)],
        y=[1] * len(career_path),
        mode='markers+text',
        marker=dict(
            size=40,
            color=list(range(len(career_path))),
            colorscale='Viridis',
            showscale=False
        ),
        text=career_path,
        textposition="top center",
        textfont=dict(size=12),
        hovertemplate='%{text}<br>ì˜ˆìƒ ì—°ì°¨: %{x}ë…„<extra></extra>'
    ))
    
    # ì—°ê²°ì„  ì¶”ê°€
    fig.add_trace(go.Scatter(
        x=years[:len(career_path)],
        y=[1] * len(career_path),
        mode='lines',
        line=dict(color='lightgray', width=2),
        showlegend=False,
        hoverinfo='skip'
    ))
    
    fig.update_layout(
        title={
            'text': 'ğŸ¯ ê²½ë ¥ ê°œë°œ ê²½ë¡œ',
            'font': {'size': 20},
            'x': 0.5,
            'xanchor': 'center'
        },
        height=300,
        margin=dict(l=0, r=0, t=50, b=0),
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        xaxis=dict(
            title='ì—°ì°¨',
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            range=[-1, max(years) + 1]
        ),
        yaxis=dict(
            showticklabels=False,
            showgrid=False,
            range=[0.5, 1.5]
        ),
        showlegend=False
    )
    
    return fig

# ========================
# LangGraph ë…¸ë“œ í•¨ìˆ˜ë“¤
# ========================

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@st.cache_resource
def get_supabase_client():
    return create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

@st.cache_resource
def get_crawler():
    return CareerInfoCrawler(NAVER_CLIENT_ID, NAVER_CLIENT_SECRET) if NAVER_CLIENT_ID and NAVER_CLIENT_SECRET else None

def search_database(state: CareerState) -> CareerState:
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ì—… ì •ë³´ ê²€ìƒ‰"""
    career_name = state["career_name"]
    supabase = get_supabase_client()
    
    if not supabase:
        state["messages"].append(
            AIMessage(content="âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        )
        state["results"] = {"data": None}
        return state
    
    state["messages"].append(
        HumanMessage(content=f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{career_name}' ê²€ìƒ‰ ì¤‘...")
    )
    
    try:
        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        exact_match = supabase.table('career_pros_cons').select("*").eq('career_name', career_name).execute()
        if exact_match.data:
            state["search_method"] = "database"
            state["results"] = {"data": exact_match.data}
            state["messages"].append(
                AIMessage(content=f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{career_name}' ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! ({len(exact_match.data)}ê°œ í•­ëª©)")
            )
            return state
        
        state["messages"].append(
            AIMessage(content=f"âŒ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ '{career_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
        )
        state["results"] = {"data": None}
        return state
        
    except Exception as e:
        state["error"] = str(e)
        state["messages"].append(
            AIMessage(content=f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        )
        state["results"] = {"data": None}
        return state

def crawl_web(state: CareerState) -> CareerState:
    """ì›¹ì—ì„œ ì§ì—… ì •ë³´ í¬ë¡¤ë§"""
    if state["results"].get("data"):  # ì´ë¯¸ DBì—ì„œ ì°¾ì€ ê²½ìš°
        return state
    
    career_name = state["career_name"]
    state["search_method"] = "web_crawling"
    crawler = get_crawler()
    
    if not crawler:
        state["messages"].append(
            AIMessage(content="âš ï¸ ì›¹ í¬ë¡¤ë§ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        )
        return state
    
    state["messages"].append(
        HumanMessage(content=f"ğŸŒ ì›¹ì—ì„œ '{career_name}' ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
    )
    
    # API í‚¤ê°€ ì—†ì„ ë•Œ ìƒ˜í”Œ ë°ì´í„°
    if not OPENAI_API_KEY:
        # ì§ì—…ë³„ ìƒ˜í”Œ ë°ì´í„°
        sample_data = {
            "ë°ì´í„° ë¶„ì„ê°€": {
                "pros": [
                    "ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì„ í†µí•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì°½ì¶œ",
                    "ë‹¤ì–‘í•œ ë„êµ¬ì™€ ê¸°ìˆ ì„ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê¸°íšŒ",
                    "ë†’ì€ ìˆ˜ìš”ì™€ ì¢‹ì€ ì²˜ìš°",
                    "ì¬íƒê·¼ë¬´ ë“± ìœ ì—°í•œ ê·¼ë¬´ í™˜ê²½",
                    "ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ë¡œì˜ ì´ì§ ê°€ëŠ¥ì„±"
                ],
                "cons": [
                    "ëŠì„ì—†ëŠ” ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµ í•„ìš”",
                    "ë°ì´í„° í’ˆì§ˆ ì´ìŠˆë¡œ ì¸í•œ ìŠ¤íŠ¸ë ˆìŠ¤",
                    "ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ê¸°ìˆ  ì‚¬ì´ì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì–´ë ¤ì›€",
                    "ë°˜ë³µì ì¸ ë¦¬í¬íŠ¸ ì‘ì„± ì—…ë¬´",
                    "ì„±ê³¼ë¥¼ ì •ëŸ‰í™”í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš°ê°€ ë§ìŒ"
                ]
            },
            "AI ê°œë°œì": {
                "pros": [
                    "ìµœì²¨ë‹¨ ê¸°ìˆ ì„ ë‹¤ë£¨ëŠ” í¥ë¯¸ë¡œìš´ ì—…ë¬´",
                    "ë†’ì€ ì—°ë´‰ê³¼ ì¢‹ì€ ë³µì§€ í˜œíƒ",
                    "ê¸€ë¡œë²Œ ê¸°ì—… ì·¨ì—… ê¸°íšŒ",
                    "ì—°êµ¬ì™€ ê°œë°œì„ ë³‘í–‰í•  ìˆ˜ ìˆìŒ",
                    "ì‚¬íšŒ ë³€í™”ë¥¼ ì´ë„ëŠ” í˜ì‹ ì ì¸ ì¼"
                ],
                "cons": [
                    "ë¹ ë¥¸ ê¸°ìˆ  ë³€í™”ì— ëŒ€í•œ ì§€ì†ì  í•™ìŠµ ì••ë°•",
                    "ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì— ëŒ€í•œ ì••ë°•ê°",
                    "ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ì œì•½ìœ¼ë¡œ ì¸í•œ í•œê³„",
                    "ì„¤ëª… ê°€ëŠ¥ì„±ê³¼ ìœ¤ë¦¬ì  ë¬¸ì œ ê³ ë¯¼",
                    "ê²½ìŸì´ ë§¤ìš° ì¹˜ì—´í•œ ë¶„ì•¼"
                ]
            },
            "ë°±ì—”ë“œ ê°œë°œì": {
                "pros": [
                    "ì•ˆì •ì ì´ê³  ë†’ì€ ìˆ˜ìš”ê°€ ìˆëŠ” ì§êµ°",
                    "ëª…í™•í•œ ì»¤ë¦¬ì–´ íŒ¨ìŠ¤ì™€ ì„±ì¥ ê°€ëŠ¥ì„±",
                    "ë‹¤ì–‘í•œ ê¸°ìˆ  ìŠ¤íƒ ê²½í—˜ ê°€ëŠ¥",
                    "ë¬¸ì œ í•´ê²°ì˜ ì„±ì·¨ê°ì´ í¼",
                    "ì›ê²© ê·¼ë¬´ ê¸°íšŒê°€ ë§ìŒ"
                ],
                "cons": [
                    "24/7 ì„œë¹„ìŠ¤ ìš´ì˜ìœ¼ë¡œ ì¸í•œ ì˜¨ì½œ ëŒ€ì‘",
                    "ë ˆê±°ì‹œ ì½”ë“œ ìœ ì§€ë³´ìˆ˜ì˜ ì–´ë ¤ì›€",
                    "í”„ë¡ íŠ¸ì—”ë“œì— ë¹„í•´ ê°€ì‹œì  ì„±ê³¼ ë¶€ì¡±",
                    "ì§€ì†ì ì¸ ê¸°ìˆ  ë¶€ì±„ ê´€ë¦¬ í•„ìš”",
                    "ë””ë²„ê¹…ê³¼ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ì— ë§ì€ ì‹œê°„ ì†Œìš”"
                ]
            },
            "ìë°” ê°œë°œì": {
                "pros": [
                    "ì•ˆì •ì ì¸ ê¸°ìˆ  ìŠ¤íƒ",
                    "ëŒ€ê¸°ì—…ê³¼ ê¸ˆìœµê¶Œ ìˆ˜ìš” ë†’ìŒ",
                    "ì²´ê³„ì ì¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤",
                    "í’ë¶€í•œ ë ˆí¼ëŸ°ìŠ¤ì™€ ì»¤ë®¤ë‹ˆí‹°",
                    "Spring ìƒíƒœê³„ì˜ ê°•ë ¥í•¨"
                ],
                "cons": [
                    "ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜",
                    "ë³´ìˆ˜ì ì¸ ê¸°ìˆ  í™˜ê²½",
                    "ê¸´ ë¹Œë“œ ì‹œê°„",
                    "ë¬´ê±°ìš´ í”„ë ˆì„ì›Œí¬",
                    "ìµœì‹  ê¸°ìˆ  ë„ì… ì–´ë ¤ì›€"
                ]
            }
        }
        
        # ê¸°ë³¸ ë°ì´í„°
        default_data = {
            "pros": [
                "ì „ë¬¸ì„±ì„ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ì•ˆì •ì ì¸ ìˆ˜ì…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤",
                "ê²½ë ¥ ê°œë°œ ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤",
                "ì‚¬íšŒì  ê¸°ì—¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            ],
            "cons": [
                "ì—…ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ì›Œë¼ë°¸ ìœ ì§€ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ê²½ìŸì´ ì¹˜ì—´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "ì§€ì†ì ì¸ ìê¸°ê³„ë°œì´ í•„ìš”í•©ë‹ˆë‹¤",
                "ì´ˆê¸° ì—°ë´‰ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            ]
        }
        
        # ì§ì—…ëª…ì— ë§ëŠ” ë°ì´í„° ì°¾ê¸°
        career_data = default_data
        for key, data in sample_data.items():
            if key in career_name:
                career_data = data
                break
        
        state["pros"] = career_data["pros"]
        state["cons"] = career_data["cons"]
        state["salary_info"] = crawler.get_career_salary_info(career_name)
        state["career_path"] = crawler.get_career_path(career_name)
        
        # ìƒ˜í”Œ ì±„ìš© ê³µê³  (API í‚¤ê°€ ì—†ì„ ë•Œ)
        state["job_postings"] = [
            {
                "company": "ë„¤ì´ë²„",
                "title": f"{career_name} ì‹ ì… ì±„ìš© (2025ë…„ ìƒë°˜ê¸°)",
                "description": f"{career_name} í¬ì§€ì…˜ì—ì„œ í•¨ê»˜ ì„±ì¥í•  ì¸ì¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤. ì‹ ì… ë° ê²½ë ¥ 1-2ë…„ ì§€ì› ê°€ëŠ¥.",
                "link": f"https://www.saramin.co.kr/zf_user/search?searchType=search&searchword={urllib.parse.quote(career_name)}",
                "salary": "ì‹ ì… ê¸°ì¤€ 4,000ë§Œì›~",
                "location": "íŒêµ",
                "type": "ì •ê·œì§",
                "source": "saramin.co.kr"
            },
            {
                "company": "ì¹´ì¹´ì˜¤",
                "title": f"ì£¼ë‹ˆì–´ {career_name} ëª¨ì§‘",
                "description": "ì¹´ì¹´ì˜¤ì™€ í•¨ê»˜ ì„¸ìƒì„ ë³€í™”ì‹œí‚¬ ì£¼ë‹ˆì–´ ê°œë°œìë¥¼ ëª¨ì§‘í•©ë‹ˆë‹¤.",
                "link": f"https://www.wanted.co.kr/search?query={urllib.parse.quote(career_name)}",
                "salary": "í˜‘ì˜",
                "location": "íŒêµ",
                "type": "ì •ê·œì§",
                "source": "wanted.co.kr"
            }
        ]
        
        state["messages"].append(
            AIMessage(content="ğŸ“Œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤ (API í‚¤ ì„¤ì • í•„ìš”)")
        )
        return state
    
    # ì‹¤ì œ í¬ë¡¤ë§ ë¡œì§
    all_pros = []
    all_cons = []
    sources = []
    
    # ì§ì—… ì •ë³´ ê²€ìƒ‰
    search_results = crawler.search_career_info(career_name)
    
    if search_results:
        state["messages"].append(
            AIMessage(content=f"â†’ {len(search_results)}ê°œ í¬ìŠ¤íŠ¸ ë°œê²¬")
        )
        
        # ê° í¬ìŠ¤íŠ¸ ì²˜ë¦¬
        for idx, post in enumerate(search_results[:10]):
            state["messages"].append(
                AIMessage(content=f"ğŸ“– ë¶„ì„ ì¤‘: {post['title'][:40]}...")
            )
            
            # í¬ë¡¤ë§
            content = crawler.crawl_content(post['link'])
            if not content:
                continue
            
            crawler.stats['total_crawled'] += 1
            
            # ì¥ë‹¨ì  ì¶”ì¶œ
            pros_cons = crawler.extract_career_pros_cons_with_gpt(career_name, content)
            
            if pros_cons:
                all_pros.extend(pros_cons['pros'])
                all_cons.extend(pros_cons['cons'])
                sources.append({
                    'title': post['title'],
                    'link': post['link'],
                    'date': post.get('postdate', '')
                })
                
                state["messages"].append(
                    AIMessage(content=f"âœ“ ì¥ì  {len(pros_cons['pros'])}ê°œ, ë‹¨ì  {len(pros_cons['cons'])}ê°œ ì¶”ì¶œ")
                )
            
            time.sleep(0.5)
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
    unique_pros = crawler.deduplicate_points(all_pros)
    unique_cons = crawler.deduplicate_points(all_cons)
    
    state["pros"] = unique_pros
    state["cons"] = unique_cons
    state["sources"] = sources[:10]
    state["salary_info"] = crawler.get_career_salary_info(career_name)
    state["career_path"] = crawler.get_career_path(career_name)
    
    # ì‹¤ì‹œê°„ ì±„ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    try:
        state["job_postings"] = crawler.get_realtime_job_postings(career_name)
    except:
        state["job_postings"] = []
    
    if state["pros"] or state["cons"]:
        state["messages"].append(
            AIMessage(content=f"ğŸ‰ ì›¹ í¬ë¡¤ë§ ì™„ë£Œ! ì´ ì¥ì  {len(state['pros'])}ê°œ, ë‹¨ì  {len(state['cons'])}ê°œ ìˆ˜ì§‘")
        )
        
        # DBì— ì €ì¥
        try:
            supabase = get_supabase_client()
            if supabase:
                data = []
                
                for pro in state["pros"]:
                    data.append({
                        'career_name': career_name,
                        'type': 'pro',
                        'content': pro
                    })
                
                for con in state["cons"]:
                    data.append({
                        'career_name': career_name,
                        'type': 'con',
                        'content': con
                    })
                
                if data:
                    supabase.table('career_pros_cons').insert(data).execute()
                    state["messages"].append(
                        AIMessage(content="ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì™„ë£Œ!")
                    )
                    st.session_state.saved_careers += 1
        except Exception as e:
            state["messages"].append(
                AIMessage(content=f"âš ï¸ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            )
    else:
        state["messages"].append(
            AIMessage(content=f"ğŸ˜¢ '{career_name}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        )
    
    return state

def process_results(state: CareerState) -> CareerState:
    """ê²°ê³¼ ì²˜ë¦¬ ë° ì •ë¦¬"""
    if state["search_method"] == "database" and state["results"].get("data"):
        # DB ê²°ê³¼ ì²˜ë¦¬
        data = state["results"]["data"]
        state["pros"] = [item['content'] for item in data if item['type'] == 'pro']
        state["cons"] = [item['content'] for item in data if item['type'] == 'con']
        state["sources"] = []
        
        # ì—°ë´‰ ì •ë³´ì™€ ê²½ë ¥ ê²½ë¡œëŠ” í¬ë¡¤ëŸ¬ë¥¼ í†µí•´ ê°€ì ¸ì˜´
        crawler = get_crawler()
        if crawler:
            state["salary_info"] = crawler.get_career_salary_info(state["career_name"])
            state["career_path"] = crawler.get_career_path(state["career_name"])
            # ì‹¤ì‹œê°„ ì±„ìš© ì •ë³´
            try:
                state["job_postings"] = crawler.get_realtime_job_postings(state["career_name"])
            except:
                state["job_postings"] = []
        
        state["messages"].append(
            AIMessage(content=f"ğŸ“‹ ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ: ì¥ì  {len(state['pros'])}ê°œ, ë‹¨ì  {len(state['cons'])}ê°œ")
        )
    
    return state

def should_search_web(state: CareerState) -> str:
    """ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨"""
    if state["results"].get("data"):
        return "process"
    else:
        return "crawl"

# ========================
# LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
# ========================

@st.cache_resource
def create_career_workflow():
    workflow = StateGraph(CareerState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("search_db", search_database)
    workflow.add_node("crawl_web", crawl_web)
    workflow.add_node("process", process_results)
    
    # ì—£ì§€ ì„¤ì •
    workflow.set_entry_point("search_db")
    workflow.add_conditional_edges(
        "search_db",
        should_search_web,
        {
            "crawl": "crawl_web",
            "process": "process"
        }
    )
    workflow.add_edge("crawl_web", "process")
    workflow.add_edge("process", END)
    
    return workflow.compile()

# ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
career_app = create_career_workflow()

# ========================
# Streamlit UI
# ========================

# ê²€ìƒ‰ ì„¹ì…˜
col1, col2, col3 = st.columns([1, 5, 1])

with col2:
    st.markdown('<div class="search-section">', unsafe_allow_html=True)
    
    # ì œëª©
    st.markdown("""
    <h2 class="search-title">
        ì–´ë–¤ ì§ì—…ì„ ì•Œì•„ë³´ê³  ê³„ì‹ ê°€ìš”?
    </h2>
    """, unsafe_allow_html=True)
    
    # ë¶ë§ˆí¬ì—ì„œ ì„ íƒëœ í•­ëª©ì´ ìˆìœ¼ë©´ ìë™ ì…ë ¥
    default_value = ""
    if 'selected_bookmark' in st.session_state:
        default_value = st.session_state.selected_bookmark
        del st.session_state.selected_bookmark
    elif 'search_query' in st.session_state:
        default_value = st.session_state.search_query
    
    # ê²€ìƒ‰ì°½
    st.markdown('<div class="big-search">', unsafe_allow_html=True)
    career_name = st.text_input(
        "ì§ì—…ëª… ì…ë ¥",
        placeholder="ì˜ˆ: ê°œë°œì, ì˜ì‚¬, êµì‚¬, ë””ìì´ë„ˆ, ë³€í˜¸ì‚¬",
        value=default_value,
        label_visibility="collapsed",
        key="career_search_input"
    )
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ë²„íŠ¼ë“¤
    st.markdown('<div class="search-buttons" style="margin-top: 1.8rem;">', unsafe_allow_html=True)
    col_btn1, col_btn2, col_btn3 = st.columns([3, 2.5, 0.5])
    with col_btn1:
        search_button = st.button("ğŸ” ê²€ìƒ‰í•˜ê¸°", use_container_width=True, type="primary")
    with col_btn2:
        show_process = st.checkbox("ğŸ”§ í”„ë¡œì„¸ìŠ¤ ë³´ê¸°", value=True)
    with col_btn3:
        if career_name and st.button("ğŸ“Œ", help="ë¶ë§ˆí¬ì— ì¶”ê°€", key="bookmark_btn"):
            if career_name not in st.session_state.bookmarks:
                st.session_state.bookmarks.append(career_name)
                st.success("ë¶ë§ˆí¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.session_state.total_searches += 1
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ì¸ê¸° ê²€ìƒ‰ì–´
    st.markdown("""
    <div class="popular-search-buttons" style="text-align: center; margin-top: 2rem;">
        <p style="opacity: 0.7; font-size: 1.2rem; margin-bottom: 1rem; color: #666; font-weight: 500;">ì¸ê¸° ì§ì—…</p>
    """, unsafe_allow_html=True)
    
    popular_careers = ["ë°ì´í„° ë¶„ì„ê°€", "ë°ì´í„° ì—”ì§€ë‹ˆì–´", "DBA", "DB ì—”ì§€ë‹ˆì–´", "AI ê°œë°œì", "AI ì—”ì§€ë‹ˆì–´", "ìë°” ê°œë°œì", "ë°±ì—”ë“œ ê°œë°œì"]
    cols = st.columns(4)
    for idx, (col, career) in enumerate(zip(cols * 2, popular_careers)):
        with col:
            if st.button(
                career, 
                key=f"popular_{idx}", 
                use_container_width=True,
                help=f"{career} ê²€ìƒ‰í•˜ê¸°"
            ):
                st.session_state.search_query = career
                st.rerun()
    
    st.markdown('</div></div>', unsafe_allow_html=True)

# ê²€ìƒ‰ ì‹¤í–‰
if search_button:
    # ì¸ê¸° ê²€ìƒ‰ì–´ë¡œ ì„ íƒëœ ê²½ìš° í•´ë‹¹ ê²€ìƒ‰ì–´ ì‚¬ìš©
    if 'search_query' in st.session_state and st.session_state.search_query:
        search_term = st.session_state.search_query
        st.session_state.search_query = ""
    else:
        search_term = career_name
    
    if search_term:
        loading_placeholder = show_loading_animation()
        
        # LangGraph ì‹¤í–‰
        initial_state = {
            "career_name": search_term,
            "search_method": "",
            "results": {},
            "pros": [],
            "cons": [],
            "sources": [],
            "salary_info": {},
            "career_path": [],
            "job_postings": [],
            "messages": [],
            "error": ""
        }
        
        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        final_state = career_app.invoke(initial_state)
        
        # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ ì œê±°
        loading_placeholder.empty()
        
        # í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ í‘œì‹œ
        if show_process and final_state["messages"]:
            with st.expander("ğŸ”§ ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤", expanded=False):
                for msg in final_state["messages"]:
                    if isinstance(msg, HumanMessage):
                        st.write(f"ğŸ‘¤ {msg.content}")
                    else:
                        st.write(f"ğŸ¤– {msg.content}")
        
        # ê²°ê³¼ í‘œì‹œ
        if final_state["pros"] or final_state["cons"]:
            # ê²€ìƒ‰ ì •ë³´
            st.markdown(f"""
            <div class="process-info fade-in">
                <strong><i class="fas fa-info-circle"></i> ê²€ìƒ‰ ë°©ë²•:</strong> {
                    'ë°ì´í„°ë² ì´ìŠ¤' if final_state["search_method"] == "database" else 'ì›¹ í¬ë¡¤ë§'
                } | 
                <strong><i class="fas fa-thumbs-up"></i> ì¥ì :</strong> {len(final_state["pros"])}ê°œ | 
                <strong><i class="fas fa-thumbs-down"></i> ë‹¨ì :</strong> {len(final_state["cons"])}ê°œ
            </div>
            """, unsafe_allow_html=True)
            
            # ì—°ë´‰ ì •ë³´ ë° ê²½ë ¥ ê²½ë¡œ
            st.markdown("---")
            st.markdown("### ğŸ’¼ ì§ì—… ê°œìš”")
            
            col1, col2 = st.columns([1, 1])
            
            with col1:
                # ì—°ë´‰ ì°¨íŠ¸
                if final_state.get("salary_info"):
                    salary_chart = create_salary_chart(final_state["salary_info"], final_state["career_name"])
                    st.plotly_chart(salary_chart, use_container_width=True)
            
            with col2:
                # ê²½ë ¥ ê²½ë¡œ
                if final_state.get("career_path"):
                    career_timeline = create_career_path_timeline(final_state["career_path"])
                    st.plotly_chart(career_timeline, use_container_width=True)
            
            # ì¥ë‹¨ì  ìƒì„¸ í‘œì‹œ
            st.markdown("---")
            st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                <div class="pros-section fade-in">
                    <h3 style="color: #28a745; margin-bottom: 1.5rem;">
                        <i class="fas fa-check-circle"></i> ì¥ì 
                    </h3>
                </div>
                """, unsafe_allow_html=True)
                
                if final_state["pros"]:
                    for idx, pro in enumerate(final_state["pros"], 1):
                        st.markdown(f"""
                        <div class="pros-item">
                            <span style="color: #28a745; font-weight: bold;">
                                <i class="fas fa-check"></i> {idx}.
                            </span> {pro}
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.write("ì¥ì  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with col2:
                st.markdown("""
                <div class="cons-section fade-in">
                    <h3 style="color: #dc3545; margin-bottom: 1.5rem;">
                        <i class="fas fa-times-circle"></i> ë‹¨ì 
                    </h3>
                </div>
                """, unsafe_allow_html=True)
                
                if final_state["cons"]:
                    for idx, con in enumerate(final_state["cons"], 1):
                        st.markdown(f"""
                        <div class="cons-item">
                            <span style="color: #dc3545; font-weight: bold;">
                                <i class="fas fa-times"></i> {idx}.
                            </span> {con}
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.write("ë‹¨ì  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # êµ¬ì²´ì ì¸ ì—…ë¬´ ë‚´ìš© í‘œì‹œ
            st.markdown("---")
            st.markdown("### ğŸ’» êµ¬ì²´ì ì¸ ì—…ë¬´ ë‚´ìš©")
            
            # ì§ì—…ë³„ êµ¬ì²´ì ì¸ ì—…ë¬´ ì •ì˜
            job_tasks = {
                "ë°ì´í„° ë¶„ì„ê°€": [
                    "ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ ì‘ì—…",
                    "SQLì„ í™œìš©í•œ ë°ì´í„° ì¶”ì¶œ ë° ê°€ê³µ",
                    "Python/Rì„ ì´ìš©í•œ í†µê³„ ë¶„ì„ ìˆ˜í–‰",
                    "ëŒ€ì‹œë³´ë“œ ë° ì‹œê°í™” ë¦¬í¬íŠ¸ ì‘ì„± (Tableau, Power BI)",
                    "A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„ ë° ê²°ê³¼ ë¶„ì„",
                    "ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë° ì˜ì‚¬ê²°ì • ì§€ì›",
                    "ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ë° ê²€ì¦"
                ],
                "ë°ì´í„° ì—”ì§€ë‹ˆì–´": [
                    "ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„ ë° êµ¬ì¶•",
                    "ETL/ELT í”„ë¡œì„¸ìŠ¤ ê°œë°œ ë° ê´€ë¦¬",
                    "ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• (Hadoop, Spark)",
                    "ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (Kafka, Flink)",
                    "ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤/ë ˆì´í¬ ì•„í‚¤í…ì²˜ ì„¤ê³„",
                    "í´ë¼ìš°ë“œ ê¸°ë°˜ ë°ì´í„° ì¸í”„ë¼ êµ¬ì¶• (AWS, GCP, Azure)",
                    "ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê°œë°œ"
                ],
                "DBA": [
                    "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì¹˜, êµ¬ì„± ë° ì—…ê·¸ë ˆì´ë“œ",
                    "ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ íŠœë‹ ë° ìµœì í™”",
                    "ë°±ì—… ë° ë³µêµ¬ ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰",
                    "ë°ì´í„°ë² ì´ìŠ¤ ë³´ì•ˆ ì •ì±… ìˆ˜ë¦½ ë° ê´€ë¦¬",
                    "ìš©ëŸ‰ ê³„íš ë° ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬",
                    "ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ì¥ì•  ëŒ€ì‘",
                    "SQL ì¿¼ë¦¬ ìµœì í™” ì§€ì›"
                ],
                "DB ì—”ì§€ë‹ˆì–´": [
                    "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ë° ëª¨ë¸ë§",
                    "ì €ì¥ í”„ë¡œì‹œì €, í•¨ìˆ˜, íŠ¸ë¦¬ê±° ê°œë°œ",
                    "ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ë° ì‹¤í–‰",
                    "ì¸ë±ìŠ¤ ì„¤ê³„ ë° ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™”",
                    "ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ API ê°œë°œ",
                    "NoSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° êµ¬í˜„",
                    "ë°ì´í„° ì •í•©ì„± ë° ë¬´ê²°ì„± ê´€ë¦¬"
                ],
                "AI ê°œë°œì": [
                    "ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„¤ê³„ ë° ê°œë°œ",
                    "ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ê³µí•™ (Feature Engineering)",
                    "ëª¨ë¸ í•™ìŠµ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹",
                    "TensorFlow, PyTorch ë“± í”„ë ˆì„ì›Œí¬ í™œìš©",
                    "ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ê°œì„ ",
                    "AI ì„œë¹„ìŠ¤ API ê°œë°œ ë° ë°°í¬",
                    "MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"
                ],
                "AI ì—”ì§€ë‹ˆì–´": [
                    "AI ëª¨ë¸ ì„œë¹™ ì¸í”„ë¼ êµ¬ì¶•",
                    "ëª¨ë¸ ê²½ëŸ‰í™” ë° ìµœì í™” (ì–‘ìí™”, í”„ë£¨ë‹)",
                    "ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© AI ëª¨ë¸ ë°°í¬",
                    "ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œìŠ¤í…œ ê°œë°œ",
                    "ë¶„ì‚° í•™ìŠµ í™˜ê²½ êµ¬ì¶• ë° ê´€ë¦¬",
                    "AI ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ë° A/B í…ŒìŠ¤íŠ¸",
                    "GPU/TPU í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ë° ìµœì í™”"
                ],
                "ìë°” ê°œë°œì": [
                    "Spring Framework ê¸°ë°˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ",
                    "RESTful API ì„¤ê³„ ë° êµ¬í˜„",
                    "JPA/Hibernateë¥¼ í™œìš©í•œ ë°ì´í„° ì•¡ì„¸ìŠ¤ ê³„ì¸µ ê°œë°œ",
                    "ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± (JUnit, Mockito)",
                    "ë©€í‹°ìŠ¤ë ˆë“œ í”„ë¡œê·¸ë˜ë° ë° ë™ì‹œì„± ì œì–´",
                    "Maven/Gradle ë¹Œë“œ ë„êµ¬ í™œìš©",
                    "ì½”ë“œ ë¦¬ë·° ë° ë¦¬íŒ©í† ë§"
                ],
                "ë°±ì—”ë“œ ê°œë°œì": [
                    "ì„œë²„ ì‚¬ì´ë“œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ êµ¬í˜„",
                    "ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° ì¿¼ë¦¬ ì‘ì„±",
                    "API ì„¤ê³„ ë° ë¬¸ì„œí™” (Swagger)",
                    "ì¸ì¦/ì¸ê°€ ì‹œìŠ¤í…œ êµ¬í˜„ (JWT, OAuth)",
                    "ìºì‹± ì „ëµ ìˆ˜ë¦½ ë° êµ¬í˜„ (Redis)",
                    "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„",
                    "CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° ë°°í¬ ìë™í™”"
                ]
            }
            
            # í˜„ì¬ ì§ì—…ì— í•´ë‹¹í•˜ëŠ” ì—…ë¬´ ì°¾ê¸°
            current_tasks = []
            career_lower = final_state["career_name"].lower()
            
            for job_key, tasks in job_tasks.items():
                if job_key.lower() in career_lower or career_lower in job_key.lower():
                    current_tasks = tasks
                    break
            
            # ê¸°ë³¸ ì—…ë¬´ (ë§¤ì¹­ë˜ëŠ” ì§ì—…ì´ ì—†ì„ ê²½ìš°)
            if not current_tasks:
                current_tasks = [
                    "í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì„ í™œìš©í•œ ì—…ë¬´ ìˆ˜í–‰",
                    "í”„ë¡œì íŠ¸ ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰",
                    "íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—… ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜",
                    "ì—…ë¬´ ê´€ë ¨ ë¬¸ì„œ ì‘ì„± ë° ë³´ê³ ",
                    "ì§€ì†ì ì¸ í•™ìŠµ ë° ì—­ëŸ‰ ê°œë°œ",
                    "í’ˆì§ˆ ê´€ë¦¬ ë° ê°œì„  í™œë™",
                    "ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ëŒ€ì‘"
                ]
            
            # ì—…ë¬´ ë‚´ìš©ì„ 2ì—´ë¡œ í‘œì‹œ
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                <div style="background: linear-gradient(135deg, #e6f3ff 0%, #c5e0ff 100%); 
                            padding: 1.5rem; border-radius: 15px; margin-bottom: 1rem;">
                    <h5 style="color: #2196F3; margin-bottom: 1rem;">
                        <i class="fas fa-tasks"></i> ì£¼ìš” ì—…ë¬´
                    </h5>
                </div>
                """, unsafe_allow_html=True)
                
                for idx, task in enumerate(current_tasks[:len(current_tasks)//2], 1):
                    st.markdown(f"""
                    <div style="background: white; padding: 1rem; margin: 0.5rem 0; 
                                border-radius: 8px; border-left: 4px solid #2196F3;
                                box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <span style="color: #2196F3; font-weight: bold;">
                            <i class="fas fa-chevron-right"></i> {idx}.
                        </span> {task}
                    </div>
                    """, unsafe_allow_html=True)
            
            with col2:
                st.markdown("""
                <div style="background: linear-gradient(135deg, #e6f3ff 0%, #c5e0ff 100%); 
                            padding: 1.5rem; border-radius: 15px; margin-bottom: 1rem;">
                    <h5 style="color: #2196F3; margin-bottom: 1rem;">
                        <i class="fas fa-clipboard-list"></i> ì¶”ê°€ ì—…ë¬´
                    </h5>
                </div>
                """, unsafe_allow_html=True)
                
                for idx, task in enumerate(current_tasks[len(current_tasks)//2:], len(current_tasks)//2 + 1):
                    st.markdown(f"""
                    <div style="background: white; padding: 1rem; margin: 0.5rem 0; 
                                border-radius: 8px; border-left: 4px solid #2196F3;
                                box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
                        <span style="color: #2196F3; font-weight: bold;">
                            <i class="fas fa-chevron-right"></i> {idx}.
                        </span> {task}
                    </div>
                    """, unsafe_allow_html=True)
            
            # ì‹¤ì‹œê°„ ì±„ìš© ê³µê³  ì„¹ì…˜
            st.markdown("---")
            st.markdown("### ğŸ’¼ ì‹¤ì‹œê°„ ì±„ìš© ê³µê³ ")
            
            # ì§ì—…ë³„ ë§ì¶¤ ì¸ì‚¬ì´íŠ¸
            career_insights = {
                "ë°ì´í„° ë¶„ì„ê°€": {
                    "suitable_for": [
                        "ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ì¸ ì‚¬ê³ ë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ",
                        "ìˆ«ìì™€ í†µê³„ì— ê´€ì‹¬ì´ ë§ì€ ì‚¬ëŒ",
                        "ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ë„ì¶œì— í¥ë¯¸ê°€ ìˆëŠ” ì‚¬ëŒ",
                        "ìƒˆë¡œìš´ ë„êµ¬ì™€ ê¸°ìˆ  í•™ìŠµì„ ì¦ê¸°ëŠ” ì‚¬ëŒ",
                        "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "ë°˜ë³µì ì¸ ë¦¬í¬íŠ¸ ì‘ì—…ì— ëŒ€í•œ ì¸ë‚´ì‹¬ í•„ìš”",
                        "ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ê¸°ìˆ  ì–‘ìª½ ì—­ëŸ‰ì´ ëª¨ë‘ í•„ìš”í•¨",
                        "ë°ì´í„° í’ˆì§ˆ ì´ìŠˆë¡œ ì¸í•œ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í•„ìš”",
                        "ëŠì„ì—†ëŠ” ê¸°ìˆ  ë³€í™”ì— ëŒ€í•œ ì ì‘ë ¥ í•„ìš”",
                        "ì„±ê³¼ë¥¼ ì •ëŸ‰í™”í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš°ê°€ ë§ìŒ"
                    ]
                },
                "ë°ì´í„° ì—”ì§€ë‹ˆì–´": {
                    "suitable_for": [
                        "ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒ",
                        "ì‹œìŠ¤í…œ ì„¤ê³„ì™€ ì•„í‚¤í…ì²˜ë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ",
                        "ìë™í™”ì™€ íš¨ìœ¨ì„±ì„ ì¶”êµ¬í•˜ëŠ” ì‚¬ëŒ",
                        "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ì‚¬ëŒ",
                        "ë°±ì—”ë“œ ê¸°ìˆ ì— í¥ë¯¸ê°€ ìˆëŠ” ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "24/7 ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ ë¶€ë‹´",
                        "ì¥ì•  ëŒ€ì‘ì„ ìœ„í•œ ì˜¨ì½œ ê·¼ë¬´ ê°€ëŠ¥ì„±",
                        "ë³µì¡í•œ ê¸°ìˆ  ìŠ¤íƒ í•™ìŠµ í•„ìš”",
                        "ê°€ì‹œì  ì„±ê³¼ê°€ ì˜ ë“œëŸ¬ë‚˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ",
                        "ì§€ì†ì ì¸ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ìŠ¤íŠ¸ë ˆìŠ¤"
                    ]
                },
                "DBA": {
                    "suitable_for": [
                        "ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„±ì„ ì¤‘ì‹œí•˜ëŠ” ì‚¬ëŒ",
                        "ì„¸ì‹¬í•˜ê³  ê¼¼ê¼¼í•œ ì„±ê²©ì˜ ì‚¬ëŒ",
                        "ìœ„ê¸° ìƒí™© ëŒ€ì²˜ ëŠ¥ë ¥ì´ ì¢‹ì€ ì‚¬ëŒ",
                        "ì²´ê³„ì ì¸ ì—…ë¬´ ì²˜ë¦¬ë¥¼ ì„ í˜¸í•˜ëŠ” ì‚¬ëŒ",
                        "ì¸í”„ë¼ ìš´ì˜ì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "24/7 ì¥ì•  ëŒ€ì‘ ì¤€ë¹„ í•„ìš”",
                        "ì‹¤ìˆ˜ì— ëŒ€í•œ ì‹¬ë¦¬ì  ë¶€ë‹´ê°ì´ í¼",
                        "ì•¼ê°„ ë° ì£¼ë§ ì‘ì—… ê°€ëŠ¥ì„±",
                        "ìƒˆë¡œìš´ ê¸°ìˆ ë³´ë‹¤ ì•ˆì •ì„± ìš°ì„ ì‹œ",
                        "ë°˜ë³µì ì¸ ëª¨ë‹ˆí„°ë§ ì—…ë¬´ì˜ ì§€ë£¨í•¨"
                    ]
                },
                "DB ì—”ì§€ë‹ˆì–´": {
                    "suitable_for": [
                        "ë°ì´í„° ëª¨ë¸ë§ì— í¥ë¯¸ê°€ ìˆëŠ” ì‚¬ëŒ",
                        "ì„±ëŠ¥ ìµœì í™”ë¥¼ ì¦ê¸°ëŠ” ì‚¬ëŒ",
                        "ë…¼ë¦¬ì  ì‚¬ê³ ë ¥ì´ ë›°ì–´ë‚œ ì‚¬ëŒ",
                        "ì„¸ë¶€ì‚¬í•­ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ëŠ” ì‚¬ëŒ",
                        "ë°±ì—”ë“œ ê°œë°œì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "ë³µì¡í•œ ì¿¼ë¦¬ ìµœì í™”ì— ëŒ€í•œ ì••ë°•",
                        "ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤íŠ¸ë ˆìŠ¤",
                        "ë‹¤ì–‘í•œ DB ê¸°ìˆ  í•™ìŠµ ë¶€ë‹´",
                        "ê°œë°œíŒ€ê³¼ì˜ ì§€ì†ì ì¸ í˜‘ì—… í•„ìš”",
                        "ì„±ëŠ¥ ì´ìŠˆì— ëŒ€í•œ ì±…ì„ê°"
                    ]
                },
                "AI ê°œë°œì": {
                    "suitable_for": [
                        "ìˆ˜í•™ê³¼ í†µê³„ì— ê°•í•œ ì‚¬ëŒ",
                        "ì—°êµ¬ì™€ ì‹¤í—˜ì„ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ",
                        "ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œì— ë¯¼ê°í•œ ì‚¬ëŒ",
                        "ì°½ì˜ì  ë¬¸ì œ í•´ê²°ì„ ì¦ê¸°ëŠ” ì‚¬ëŒ",
                        "ì§€ì†ì ì¸ í•™ìŠµì— ì—´ì •ì´ ìˆëŠ” ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "ë¹ ë¥¸ ê¸°ìˆ  ë³€í™”ì— ëŒ€í•œ í•™ìŠµ ì••ë°•",
                        "ëª¨ë¸ ì„±ëŠ¥ ê°œì„ ì— ëŒ€í•œ ì§€ì†ì  ìš”êµ¬",
                        "ë†’ì€ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë¹„ìš© ë¬¸ì œ",
                        "ì„¤ëª… ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ê³ ë¯¼ í•„ìš”",
                        "ê²½ìŸì´ ë§¤ìš° ì¹˜ì—´í•œ ë¶„ì•¼"
                    ]
                },
                "AI ì—”ì§€ë‹ˆì–´": {
                    "suitable_for": [
                        "ì‹œìŠ¤í…œ ìµœì í™”ì— ê´€ì‹¬ì´ ë§ì€ ì‚¬ëŒ",
                        "MLOpsì™€ ì¸í”„ë¼ë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ",
                        "ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œìŠ¤í…œì— í¥ë¯¸ê°€ ìˆëŠ” ì‚¬ëŒ",
                        "ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ìš´ì˜ ê²½í—˜ì„ ì›í•˜ëŠ” ì‚¬ëŒ",
                        "DevOps ë¬¸í™”ë¥¼ ì„ í˜¸í•˜ëŠ” ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "ëª¨ë¸ ì„œë¹™ ì¸í”„ë¼ ê´€ë¦¬ ë³µì¡ì„±",
                        "GPU í´ëŸ¬ìŠ¤í„° ìš´ì˜ ë¹„ìš© ë¶€ë‹´",
                        "ëª¨ë¸ ë²„ì „ ê´€ë¦¬ì˜ ì–´ë ¤ì›€",
                        "ì‹¤ì‹œê°„ ì¶”ë¡  ì„±ëŠ¥ ë³´ì¥ ì••ë°•",
                        "ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ í˜¸í™˜ì„± ë¬¸ì œ"
                    ]
                },
                "ìë°” ê°œë°œì": {
                    "suitable_for": [
                        "ì•ˆì •ì ì¸ ê¸°ìˆ  ìŠ¤íƒì„ ì„ í˜¸í•˜ëŠ” ì‚¬ëŒ",
                        "ëŒ€ê·œëª¨ ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì„ ì›í•˜ëŠ” ì‚¬ëŒ",
                        "ì²´ê³„ì ì¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ",
                        "Spring ìƒíƒœê³„ì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒ",
                        "ê¸ˆìœµ/ê³µê³µ ë„ë©”ì¸ì— ê´€ì‹¬ì´ ìˆëŠ” ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ ë¶€ë‹´",
                        "ë³´ìˆ˜ì ì¸ ê¸°ìˆ  ìŠ¤íƒì˜ í•œê³„",
                        "ê¸´ ë¹Œë“œ ì‹œê°„ê³¼ ë¬´ê±°ìš´ í”„ë ˆì„ì›Œí¬",
                        "ì—”í„°í”„ë¼ì´ì¦ˆ í™˜ê²½ì˜ ê²½ì§ì„±",
                        "ìµœì‹  ê¸°ìˆ  ë„ì…ì˜ ì–´ë ¤ì›€"
                    ]
                },
                "ë°±ì—”ë“œ ê°œë°œì": {
                    "suitable_for": [
                        "ì„œë²„ ì‚¬ì´ë“œ ë¡œì§ì— í¥ë¯¸ê°€ ìˆëŠ” ì‚¬ëŒ",
                        "ì‹œìŠ¤í…œ ì„¤ê³„ì™€ ì•„í‚¤í…ì²˜ë¥¼ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ",
                        "API ì„¤ê³„ì— ê´€ì‹¬ì´ ë§ì€ ì‚¬ëŒ",
                        "ì„±ëŠ¥ ìµœì í™”ë¥¼ ì¦ê¸°ëŠ” ì‚¬ëŒ",
                        "ë‹¤ì–‘í•œ ê¸°ìˆ  ìŠ¤íƒì„ ê²½í—˜í•˜ê³  ì‹¶ì€ ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "24/7 ì„œë¹„ìŠ¤ ìš´ì˜ì— ëŒ€í•œ ë¶€ë‹´",
                        "í”„ë¡ íŠ¸ì—”ë“œ ëŒ€ë¹„ ê°€ì‹œì„± ë¶€ì¡±",
                        "ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê´€ë¦¬",
                        "ë ˆê±°ì‹œ ì½”ë“œ ë¦¬íŒ©í† ë§ ì••ë°•",
                        "ì§€ì†ì ì¸ ê¸°ìˆ  ë¶€ì±„ í•´ê²° í•„ìš”"
                    ]
                }
            }
            
            # í˜„ì¬ ì§ì—…ì— ë§ëŠ” ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°
            current_insights = {"suitable_for": [], "considerations": []}
            career_lower = final_state["career_name"].lower()
            
            for job_key, insights in career_insights.items():
                if job_key.lower() in career_lower or career_lower in job_key.lower():
                    current_insights = insights
                    break
            
            # ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ (ë§¤ì¹­ë˜ëŠ” ì§ì—…ì´ ì—†ì„ ê²½ìš°)
            if not current_insights["suitable_for"]:
                current_insights = {
                    "suitable_for": [
                        "í•´ë‹¹ ë¶„ì•¼ì— ì—´ì •ì´ ìˆëŠ” ì‚¬ëŒ",
                        "ì§€ì†ì ì¸ í•™ìŠµì„ ì¦ê¸°ëŠ” ì‚¬ëŒ",
                        "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ì‚¬ëŒ",
                        "íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì‚¬ëŒ",
                        "ì±…ì„ê°ì´ ê°•í•œ ì‚¬ëŒ"
                    ],
                    "considerations": [
                        "ì—…ë¬´ì— ëŒ€í•œ ì „ë¬¸ì„± ê°œë°œ í•„ìš”",
                        "ì§€ì†ì ì¸ ìê¸°ê³„ë°œ ìš”êµ¬",
                        "ì—…ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ ëŠ¥ë ¥ í•„ìš”",
                        "ì›Œë¼ë°¸ ìœ ì§€ë¥¼ ìœ„í•œ ë…¸ë ¥ í•„ìš”",
                        "ê²½ë ¥ ê°œë°œ ê³„íš ìˆ˜ë¦½ í•„ìš”"
                    ]
                }
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"""
                <div class="career-insight">
                    <h5 style="color: #667eea; margin-bottom: 1rem;">
                        <i class="fas fa-star"></i> ì´ ì§ì—…ì´ ë§ëŠ” ì‚¬ëŒ
                    </h5>
                    <ul style="margin: 0; padding-left: 1.5rem;">
                """, unsafe_allow_html=True)
                
                for suitable in current_insights["suitable_for"]:
                    st.markdown(f"<li>{suitable}</li>", unsafe_allow_html=True)
                
                st.markdown("</ul></div>", unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="career-insight">
                    <h5 style="color: #667eea; margin-bottom: 1rem;">
                        <i class="fas fa-exclamation-triangle"></i> ê³ ë ¤í•  ì 
                    </h5>
                    <ul style="margin: 0; padding-left: 1.5rem;">
                """, unsafe_allow_html=True)
                
                for consideration in current_insights["considerations"]:
                    st.markdown(f"<li>{consideration}</li>", unsafe_allow_html=True)
                
                st.markdown("</ul></div>", unsafe_allow_html=True)
            
            # ê´€ë ¨ ì§ì—… ì¶”ì²œ
            st.markdown("---")
            st.markdown(f"""
            <div style="text-align: center; margin: 2rem 0;">
                <h4 style="color: {text_color}; margin-bottom: 1rem;">
                    <i class="fas fa-link"></i> ê´€ë ¨ ì§ì—… ì¶”ì²œ
                </h4>
                <p style="color: {text_color}; font-size: 0.9rem; opacity: 0.7;">
                    ë¹„ìŠ·í•œ ìŠ¤í‚¬ì…‹ì„ ê°€ì§„ ë‹¤ë¥¸ ì§ì—…ë“¤ë„ ì‚´í´ë³´ì„¸ìš”
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            # ì§ì—…ë³„ ê´€ë ¨ ì§ì—…
            related_careers = {
                "ë°ì´í„° ë¶„ì„ê°€": ["ë¹„ì¦ˆë‹ˆìŠ¤ ì• ë„ë¦¬ìŠ¤íŠ¸", "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸", "í”„ë¡œë•íŠ¸ ì• ë„ë¦¬ìŠ¤íŠ¸", "ë§ˆì¼€íŒ… ì• ë„ë¦¬ìŠ¤íŠ¸"],
                "ë°ì´í„° ì—”ì§€ë‹ˆì–´": ["ë¹…ë°ì´í„° ì—”ì§€ë‹ˆì–´", "ë°ì´í„° ì•„í‚¤í…íŠ¸", "í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´", "MLOps ì—”ì§€ë‹ˆì–´"],
                "DBA": ["ë°ì´í„° ì•„í‚¤í…íŠ¸", "DB ì»¨ì„¤í„´íŠ¸", "ì‹œìŠ¤í…œ ê´€ë¦¬ì", "í´ë¼ìš°ë“œ DBA"],
                "DB ì—”ì§€ë‹ˆì–´": ["ë°±ì—”ë“œ ê°œë°œì", "ë°ì´í„° ì—”ì§€ë‹ˆì–´", "ì†”ë£¨ì…˜ ì•„í‚¤í…íŠ¸", "DBA"],
                "AI ê°œë°œì": ["ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´", "ë”¥ëŸ¬ë‹ ë¦¬ì„œì²˜", "ì»´í“¨í„° ë¹„ì „ ì—”ì§€ë‹ˆì–´", "NLP ì—”ì§€ë‹ˆì–´"],
                "AI ì—”ì§€ë‹ˆì–´": ["MLOps ì—”ì§€ë‹ˆì–´", "AI í”Œë«í¼ ì—”ì§€ë‹ˆì–´", "ëª¨ë¸ ìµœì í™” ì—”ì§€ë‹ˆì–´", "ì—£ì§€ AI ì—”ì§€ë‹ˆì–´"],
                "ìë°” ê°œë°œì": ["ìŠ¤í”„ë§ ê°œë°œì", "ì•ˆë“œë¡œì´ë“œ ê°œë°œì", "í’€ìŠ¤íƒ ê°œë°œì", "ì—”í„°í”„ë¼ì´ì¦ˆ ê°œë°œì"],
                "ë°±ì—”ë“œ ê°œë°œì": ["DevOps ì—”ì§€ë‹ˆì–´", "í’€ìŠ¤íƒ ê°œë°œì", "API ê°œë°œì", "ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸"]
            }
            
            # í˜„ì¬ ì§ì—…ê³¼ ê´€ë ¨ëœ ì§ì—… ì°¾ê¸°
            current_related = []
            for key, values in related_careers.items():
                if key in final_state["career_name"]:
                    current_related = values
                    break
            
            if not current_related:
                current_related = ["ì»¨ì„¤í„´íŠ¸", "í”„ë¦¬ëœì„œ", "ì°½ì—…ê°€", "ì—°êµ¬ì›"]
            
            cols = st.columns(4)
            for idx, (col, related) in enumerate(zip(cols, current_related)):
                with col:
                    st.markdown(f"""
                    <div style="background: {card_bg}; padding: 1rem; border-radius: 10px; 
                                text-align: center; box-shadow: 0 2px 5px rgba(0,0,0,0.1);
                                transition: all 0.3s ease; cursor: pointer;">
                        <i class="fas fa-briefcase" style="color: #667eea; font-size: 1.5rem;"></i>
                        <p style="margin: 0.5rem 0; font-weight: 600; color: {text_color};">{related}</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            # ì¶œì²˜ (ì›¹ í¬ë¡¤ë§ì¸ ê²½ìš°)
            if final_state["sources"]:
                with st.expander("ğŸ“š ì¶œì²˜ ë³´ê¸°"):
                    for idx, source in enumerate(final_state["sources"], 1):
                        st.markdown(f"""
                        <div style="padding: 0.5rem; margin: 0.3rem 0;">
                            <i class="fas fa-link"></i> {idx}. 
                            <a href="{source['link']}" target="_blank" style="color: {secondary_text};">
                                {source['title']}
                            </a>
                        </div>
                        """, unsafe_allow_html=True)
        else:
            st.error(f"'{search_term}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    st.markdown("""
    <div class="metric-card">
        <i class="fas fa-brain" style="color: #667eea; font-size: 2rem;"></i>
        <p style="margin-top: 0.5rem;">LangGraphë¡œ êµ¬í˜„ëœ<br>ì²´ê³„ì ì¸ ë¶„ì„ í”„ë¡œì„¸ìŠ¤</p>
    </div>
    """, unsafe_allow_html=True)
with col2:
    st.markdown("""
    <div class="metric-card">
        <i class="fas fa-sync-alt" style="color: #28a745; font-size: 2rem;"></i>
        <p style="margin-top: 0.5rem;">DB ìš°ì„  ê²€ìƒ‰<br>â†’ ì—†ìœ¼ë©´ ì›¹ í¬ë¡¤ë§</p>
    </div>
    """, unsafe_allow_html=True)
with col3:
    st.markdown("""
    <div class="metric-card">
        <i class="fas fa-save" style="color: #dc3545; font-size: 2rem;"></i>
        <p style="margin-top: 0.5rem;">ê²€ìƒ‰ ê²°ê³¼<br>ìë™ ì €ì¥</p>
    </div>
    """, unsafe_allow_html=True)

current_date = datetime.now().strftime('%Yë…„ %mì›” %dì¼')
st.markdown(f"""
<div style="text-align: center; color: #666; padding: 2rem; margin-top: 2rem;">
    <p style="margin-bottom: 0.5rem;">
        <i class="fas fa-clock"></i> ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {current_date}
    </p>
    <p style="font-size: 0.9rem; opacity: 0.8;">
        Powered by LangGraph & OpenAI | Made with <i class="fas fa-heart" style="color: #e74c3c;"></i> by Career Insight Team
    </p>
</div>
""", unsafe_allow_html=True)
